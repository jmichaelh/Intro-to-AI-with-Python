{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  K-Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've seen how to build a classifier with logistic regression. Aren't there other classifiers we could try?\n",
    "\n",
    "\n",
    "#### Yes! There are many models. Here are some common ones listed below:\n",
    "* [DecisionTreeClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "* [GaussianNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "* [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "* [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "* [LogisticRegressionCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html)\n",
    "* [MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "* [NearestCentroid](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html)\n",
    "* [RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* [RidgeClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html)\n",
    "* [SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "\n",
    "In this lesson, we will get an intuitive and practical feel for the **k-Nearest Neighbors** model. \n",
    "\n",
    "- kNN is a **non-parametric model**, meaning it is non-linear. So, the model is not represented as an equation with parameters (e.g. the $\\beta$ values in linear regression).\n",
    "<br>\n",
    "\n",
    "<a id=\"k-nearest-neighbors-knn-classification\"></a>\n",
    "\n",
    "## K-Nearest Neighbors (KNN) Classification\n",
    "---\n",
    "\n",
    "K-nearest neighbors classification is (as its name implies) a classification model that uses the \"K\" most similar observations in order to make a prediction.\n",
    "\n",
    "KNN is a supervised learning method; therefore, the training data must have known target values.\n",
    "\n",
    "The process of of prediction using KNN is fairly straightforward:\n",
    "\n",
    "1. Pick a value for K.\n",
    "2. Search for the K observations in the data that are \"nearest\" to the measurements of the unknown iris.\n",
    "    - Euclidian distance is often used as the distance metric, but other metrics are allowed.\n",
    "3. Use the most popular response value from the K \"nearest neighbors\" as the predicted response value for the unknown Target Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:24:09.321535Z",
     "start_time": "2024-01-09T04:24:07.547369Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T05:10:54.278031Z",
     "start_time": "2024-01-09T05:10:54.218684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.949682</td>\n",
       "      <td>1.114303</td>\n",
       "      <td>0.834127</td>\n",
       "      <td>0.682099</td>\n",
       "      <td>1.032336</td>\n",
       "      <td>0.943534</td>\n",
       "      <td>0.963422</td>\n",
       "      <td>1.071960</td>\n",
       "      <td>1.158251</td>\n",
       "      <td>1.362725</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.289635</td>\n",
       "      <td>0.257085</td>\n",
       "      <td>0.291554</td>\n",
       "      <td>0.229645</td>\n",
       "      <td>0.243413</td>\n",
       "      <td>0.256121</td>\n",
       "      <td>0.255118</td>\n",
       "      <td>0.288982</td>\n",
       "      <td>0.293738</td>\n",
       "      <td>0.204225</td>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.174412</td>\n",
       "      <td>0.441398</td>\n",
       "      <td>0.170924</td>\n",
       "      <td>0.045027</td>\n",
       "      <td>0.315307</td>\n",
       "      <td>0.262389</td>\n",
       "      <td>0.295228</td>\n",
       "      <td>0.299476</td>\n",
       "      <td>0.365157</td>\n",
       "      <td>0.639693</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.742358</td>\n",
       "      <td>0.942071</td>\n",
       "      <td>0.615451</td>\n",
       "      <td>0.515010</td>\n",
       "      <td>0.870855</td>\n",
       "      <td>0.761064</td>\n",
       "      <td>0.784407</td>\n",
       "      <td>0.866306</td>\n",
       "      <td>0.934340</td>\n",
       "      <td>1.222623</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.940475</td>\n",
       "      <td>1.118486</td>\n",
       "      <td>0.813264</td>\n",
       "      <td>0.676835</td>\n",
       "      <td>1.035824</td>\n",
       "      <td>0.941502</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>1.065500</td>\n",
       "      <td>1.165556</td>\n",
       "      <td>1.375368</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.163295</td>\n",
       "      <td>1.307904</td>\n",
       "      <td>1.028340</td>\n",
       "      <td>0.834317</td>\n",
       "      <td>1.198270</td>\n",
       "      <td>1.123060</td>\n",
       "      <td>1.134852</td>\n",
       "      <td>1.283156</td>\n",
       "      <td>1.383173</td>\n",
       "      <td>1.504832</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.721779</td>\n",
       "      <td>1.833757</td>\n",
       "      <td>1.722725</td>\n",
       "      <td>1.634884</td>\n",
       "      <td>1.650050</td>\n",
       "      <td>1.666902</td>\n",
       "      <td>1.713342</td>\n",
       "      <td>1.785420</td>\n",
       "      <td>1.885690</td>\n",
       "      <td>1.893950</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               WTT          PTI          EQW          SBI          LQE  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.949682     1.114303     0.834127     0.682099     1.032336   \n",
       "std       0.289635     0.257085     0.291554     0.229645     0.243413   \n",
       "min       0.174412     0.441398     0.170924     0.045027     0.315307   \n",
       "25%       0.742358     0.942071     0.615451     0.515010     0.870855   \n",
       "50%       0.940475     1.118486     0.813264     0.676835     1.035824   \n",
       "75%       1.163295     1.307904     1.028340     0.834317     1.198270   \n",
       "max       1.721779     1.833757     1.722725     1.634884     1.650050   \n",
       "\n",
       "               QWG          FDJ          PJF          HQE          NXJ  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.943534     0.963422     1.071960     1.158251     1.362725   \n",
       "std       0.256121     0.255118     0.288982     0.293738     0.204225   \n",
       "min       0.262389     0.295228     0.299476     0.365157     0.639693   \n",
       "25%       0.761064     0.784407     0.866306     0.934340     1.222623   \n",
       "50%       0.941502     0.945333     1.065500     1.165556     1.375368   \n",
       "75%       1.123060     1.134852     1.283156     1.383173     1.504832   \n",
       "max       1.666902     1.713342     1.785420     1.885690     1.893950   \n",
       "\n",
       "       TARGET CLASS  \n",
       "count    1000.00000  \n",
       "mean        0.50000  \n",
       "std         0.50025  \n",
       "min         0.00000  \n",
       "25%         0.00000  \n",
       "50%         0.50000  \n",
       "75%         1.00000  \n",
       "max         1.00000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import \"Classified Data\", set the index_col to 0\n",
    "df = pd.read_csv(\"./data/Classified Data\",index_col=0)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"standardizing-features\"></a>\n",
    "## Standardizing Features\n",
    "---\n",
    "\n",
    "There is one major issue that applies to many machine learning models: They are sensitive to feature scale. \n",
    "\n",
    "> KNN in particular is sensitive to feature scale because it (by default) uses the Euclidean distance metric. To determine closeness, Euclidean distance sums the square difference along each axis. So, if one axis has large differences and another has small differences, the former axis will contribute much more to the distance than the latter axis.\n",
    "\n",
    "This means that it matters whether our feature are centered around zero and have similar variance to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:24:11.156121Z",
     "start_time": "2024-01-09T04:24:11.032507Z"
    }
   },
   "outputs": [],
   "source": [
    "#We use a scaler from sklearn\n",
    "\n",
    "##Import\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "##Instantiate\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fit + transform\n",
    "scaled_features = scaler.fit_transform(df.drop(\"TARGET CLASS\", axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:24:11.585163Z",
     "start_time": "2024-01-09T04:24:11.541103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.119105e-16</td>\n",
       "      <td>-2.939871e-16</td>\n",
       "      <td>-1.203482e-16</td>\n",
       "      <td>-1.882938e-16</td>\n",
       "      <td>-6.057377e-16</td>\n",
       "      <td>3.552714e-17</td>\n",
       "      <td>2.255973e-16</td>\n",
       "      <td>-4.760636e-16</td>\n",
       "      <td>3.197442e-16</td>\n",
       "      <td>4.503065e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000500e+00</td>\n",
       "      <td>1.000500e+00</td>\n",
       "      <td>1.000500e+00</td>\n",
       "      <td>1.000500e+00</td>\n",
       "      <td>1.000500e+00</td>\n",
       "      <td>1.000500e+00</td>\n",
       "      <td>1.000500e+00</td>\n",
       "      <td>1.000500e+00</td>\n",
       "      <td>1.000500e+00</td>\n",
       "      <td>1.000500e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.678050e+00</td>\n",
       "      <td>-2.618747e+00</td>\n",
       "      <td>-2.275858e+00</td>\n",
       "      <td>-2.775551e+00</td>\n",
       "      <td>-2.947206e+00</td>\n",
       "      <td>-2.660802e+00</td>\n",
       "      <td>-2.620466e+00</td>\n",
       "      <td>-2.674465e+00</td>\n",
       "      <td>-2.701361e+00</td>\n",
       "      <td>-3.542140e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.161683e-01</td>\n",
       "      <td>-6.702761e-01</td>\n",
       "      <td>-7.504105e-01</td>\n",
       "      <td>-7.279635e-01</td>\n",
       "      <td>-6.637361e-01</td>\n",
       "      <td>-7.127975e-01</td>\n",
       "      <td>-7.020467e-01</td>\n",
       "      <td>-7.120098e-01</td>\n",
       "      <td>-7.626629e-01</td>\n",
       "      <td>-6.863610e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.180217e-02</td>\n",
       "      <td>1.628137e-02</td>\n",
       "      <td>-7.159299e-02</td>\n",
       "      <td>-2.293699e-02</td>\n",
       "      <td>1.433731e-02</td>\n",
       "      <td>-7.940354e-03</td>\n",
       "      <td>-7.093937e-02</td>\n",
       "      <td>-2.236584e-02</td>\n",
       "      <td>2.488297e-02</td>\n",
       "      <td>6.194010e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.378939e-01</td>\n",
       "      <td>7.534412e-01</td>\n",
       "      <td>6.664646e-01</td>\n",
       "      <td>6.631695e-01</td>\n",
       "      <td>6.820374e-01</td>\n",
       "      <td>7.012930e-01</td>\n",
       "      <td>6.723000e-01</td>\n",
       "      <td>7.311915e-01</td>\n",
       "      <td>7.661087e-01</td>\n",
       "      <td>6.961851e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.667092e+00</td>\n",
       "      <td>2.799904e+00</td>\n",
       "      <td>3.049325e+00</td>\n",
       "      <td>4.151021e+00</td>\n",
       "      <td>2.538987e+00</td>\n",
       "      <td>2.825739e+00</td>\n",
       "      <td>2.940974e+00</td>\n",
       "      <td>2.470109e+00</td>\n",
       "      <td>2.477734e+00</td>\n",
       "      <td>2.602476e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                WTT           PTI           EQW           SBI           LQE  \\\n",
       "count  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03   \n",
       "mean   1.119105e-16 -2.939871e-16 -1.203482e-16 -1.882938e-16 -6.057377e-16   \n",
       "std    1.000500e+00  1.000500e+00  1.000500e+00  1.000500e+00  1.000500e+00   \n",
       "min   -2.678050e+00 -2.618747e+00 -2.275858e+00 -2.775551e+00 -2.947206e+00   \n",
       "25%   -7.161683e-01 -6.702761e-01 -7.504105e-01 -7.279635e-01 -6.637361e-01   \n",
       "50%   -3.180217e-02  1.628137e-02 -7.159299e-02 -2.293699e-02  1.433731e-02   \n",
       "75%    7.378939e-01  7.534412e-01  6.664646e-01  6.631695e-01  6.820374e-01   \n",
       "max    2.667092e+00  2.799904e+00  3.049325e+00  4.151021e+00  2.538987e+00   \n",
       "\n",
       "                QWG           FDJ           PJF           HQE           NXJ  \n",
       "count  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03  \n",
       "mean   3.552714e-17  2.255973e-16 -4.760636e-16  3.197442e-16  4.503065e-16  \n",
       "std    1.000500e+00  1.000500e+00  1.000500e+00  1.000500e+00  1.000500e+00  \n",
       "min   -2.660802e+00 -2.620466e+00 -2.674465e+00 -2.701361e+00 -3.542140e+00  \n",
       "25%   -7.127975e-01 -7.020467e-01 -7.120098e-01 -7.626629e-01 -6.863610e-01  \n",
       "50%   -7.940354e-03 -7.093937e-02 -2.236584e-02  2.488297e-02  6.194010e-02  \n",
       "75%    7.012930e-01  6.723000e-01  7.311915e-01  7.661087e-01  6.961851e-01  \n",
       "max    2.825739e+00  2.940974e+00  2.470109e+00  2.477734e+00  2.602476e+00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append the new column to the df\n",
    "df_feat = pd.DataFrame(scaled_features, columns = df.columns[:-1])\n",
    "df_feat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:24:12.334373Z",
     "start_time": "2024-01-09T04:24:12.259148Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, df[\"TARGET CLASS\"],\n",
    "                                                   test_size = .3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using kNN\n",
    "Remember that we are trying to come up with a model to predict whether someone will TARGET CLASS or not. We'll start with k = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:24:13.283206Z",
     "start_time": "2024-01-09T04:24:12.756107Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Instantiate\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "#Fit\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#predict\n",
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:24:13.313433Z",
     "start_time": "2024-01-09T04:24:13.285333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[134   8]\n",
      " [ 11 147]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       142\n",
      "           1       0.95      0.93      0.94       158\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.94      0.94      0.94       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a K value\n",
    "How do we make sure we can choose a good K value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:24:14.338930Z",
     "start_time": "2024-01-09T04:24:13.835015Z"
    }
   },
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:24:14.530351Z",
     "start_time": "2024-01-09T04:24:14.341353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm0AAAGDCAYAAAB5rSfRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABKqUlEQVR4nO3de3wU1f3/8dcnIQQCJFECqCBy8dIqWq0R8VsVqq0Fa9W2XrFYW+sNtZZq+4NerFr7ra2tfqWiVVHrteLXVqXfQrFWQS2iouLd1sQLihcCIhAg4ZLP74+ZbZaw2WySnZ3d5P18PPaxuzPnzH5mMpt8cmbOOebuiIiIiEh+K4o7ABERERFpm5I2ERERkQKgpE1ERESkAChpExERESkAStpERERECoCSNhEREZECoKRNRKQbMrM/mNnlccchIplT0iYiHWJmb5vZBjOrT3pcm+MY5ptZQ/jZK8zsz2a2Y4Z1x5nZe1HH2B5mNszM3Mx6hO/NzH5nZq+b2eAWZU8KfwbWYnkPM1tuZkflMnYRiZ6SNhHpjK+4e9+kx3mpCiWSkBbLitvzQWnKn+fufYFdgb7Ab9qz3XxlZkXADcA4YKy7L2tR5AGgEhjbYvl4wIG/RRuhiOSakjYRyTozO83M/mlmV5vZSuCS8HLc9WY2x8zWAZ83s0+HrWWfmNkrZnZ00ja2KZ/uM939E4JEZt+kbXzLzF4zs7Vm9qaZnRUu7wPMBXZKaiXcycyKzGyqmdWa2Uozu9fMtm9lH19Lbs0KW7jqzOyzZtbLzO4Mt/GJmT1jZoPacQiLgVuBamCcu3+UYn8bgHuBU1usOhW42903m9n/mtmHZrbazB4zs71a2ZfTzOyJFsvczHYNX5ea2W/MbKmZfWRmvzez3u3YHxHJAiVtIhKVA4E3gUHAL8JlE8PX/YCngL8ADwEDgfOBu8xsj6RtJJffKqloycz6A18DapIWLweOAsqBbwFXm9ln3X0dMAF4P6mV8P0whmMJWq92AlYBM1r5yD8CJye9/xKwwt2fA74JVAA7A/2Bs4EN6eJv4S5gD+Awd1+ZptxtwHGJBMrMKoCvhMshSEx3Izi+z4Xb7YgrgN0JEuJdgcHAxR3cloh0kJI2EemMB8KWpMTjjKR177v779x9s7snEpYH3f2f7t5EkAD0Ba5w943u/gjwf2ydCP2nfNiylMp0M1sNrACqCBIvANz9r+5e64EFBAniIWn252zgx+7+nrs3ApcQJEXbXN4F7gaONrOy8P1EgkQOYBNBsraru29x92fdfU2az23pCOB/w9bDVrn7P4GPgK+Gi04A/u3uS8L1t7j72qR9+UyY2GUsvGfuTGCKu3/s7muB/wZOas92RKTzlLSJSGcc6+6VSY+bkta9m6J88rKdgHfDBC7hHYJWnHTbaOm77l4B7ANsBwxJrDCzCWa2yMw+NrNPgCMJErvW7ALcn0hCgdeALQSthVtx95pw/VfCxO1ogkQO4A5gHnCPmb1vZr82s5IM9iXhKOBnZvbtDMreTvMl0knhe8ys2MyuCC/1rgHeDsuk2/9UBgBlwLNJx+Vv4XIRySElbSISFW9j2fvAzuEN9wlDgWWtlE//Ye4vAZcDM8Jel6XAnwg6Jgxy90pgDpDobZlq2+8CE1okor1SdAJISFwiPQZ4NUzkcPdN7n6pu+8J/BdBEtby3rN0FhJc5rzGzCa2UfYO4HAzOwgYQ/Ml0IlhXF8guFQ7LFxuLTcArCNIzIICZjskrVtBcGl3r6RjUhF2/hCRHFLSJiJxeQpYD/zQzErMbBxBonJPJ7Z5G0Gr2NFAT6AUqAM2m9kEgsuOCR8B/VtcLvw98Asz2wXAzAaY2TFpPu+ecJvn0NzKhpl93sz2Dnu8riG4XNqUehOphZdzvwbcaGZfT1PubYL7/f4I/N3dPwxX9QMagZUECdl/p/m4F4C9zGxfM+tFcCk1sf0m4CaC+wEHhvs32My+1J79EZHOU9ImIp3xF9t6nLb7M63o7hsJkrQJBK051wGnuvvrHQ0m3OY1wE/De6++S9DDchVBy9PspLKvEyQ6b4aX/XYK684GHjKztcAigg4VrX3eB8CTBK1ps5JW7QDcR5CwvQYsIGgRI+x5+fsM9+fvwInAbWb2lTRFbyO4tHt70rLbCS43LwNeDfeltc/5N3AZ8DDwBtt2+vh/BB08FoWXWh8m6CghIjlk7hlffRARERGRmKilTURERKQAKGkTERERKQBK2kREREQKQKRJm5mNN7N/mVmNmU1Nsb7UzGaF658ys2Hh8hIzu83MXgqnipmWVOftcPkSM1scZfwiIiIi+SKypC3s6j6DoGfYnsDJZrZni2KnA6vcfVfgauBX4fLjgVJ33xvYHzgrkdCFPu/u+7p7dVTxi4iIiOSTVFOzZMtooMbd3wQws3sIB6BMKnMMzeMB3QdcG06Z4kCfcOqY3sBGgq7zHVJVVeXDhg3raHURERGRnHn22WdXuPs2s45EmbQNZuspaN5j2/GO/lPG3TeH8wf2J0jgjgE+IBgUcoq7fxzWcYIxlBy4wd1vTPXhZnYmwXx5DB06lMWLdSVVRERE8p+ZvZNqeb52RBhNMN/fTsBw4EIzGxGuO9jdP0tw2fVcMzs01Qbc/UZ3r3b36gEDNEWeiIiIFLYok7ZlwM5J74ew9ZyCW5UJL4VWEEy5MhH4Wzh/33Lgn0A1QGIOwHD5/QQJnoiIiEiXFmXS9gywm5kNN7OewEkkTSETmg18M3x9HPCIB1M0LAUOAzCzPgSTIL9uZn3MrF/S8iOAlyPcBxEREZG8ENk9beE9aucB84Bi4BZ3f8XMLgMWu/ts4GbgDjOrAT4mSOwg6HV6q5m9Ahhwq7u/GF4ivT/oq0AP4G53/1tU+yAiIiKSL7rF3KPV1dWujggiIiJSCMzs2VTDmuVrRwQRERERSaKkTURERKQAKGnLsdpamDK5kUHlGyguamJQ+QamTG6ktjbuyERERCSfKWnLoblzYcw+6+g9czoL146i0XuycO0oes+czph91jF3btwRioiISL5SR4Qcqa0NErbZ67/AQSzaZv2TjOHosodZ9GIfRo6MIUARERHJC+qIELNrf9vIGZuuS5mwARzEIr6z6XpmXN2Y48hERESkEChpy5G772zi9E2/T1vmO5uu5+47tuQoIhERESkkStpyZEV9KbuQcv7X/xjKUlbU98pRRCIiIlJIlLTlSFXfRt5hl7RlljKUqr4NOYpIREREComSthyZ+I0ibi45O22ZmSXnMHFScY4iEhERkUKipC1HzruwlJtKJvMkY1Kuf5IxzCw5h3OnlOY4MhERESkEStpyZORIuP2+Phxd9jDTSq6klhFsoge1jGBayZUcXfYwt9+n4T5EREQkNSVtOTRhAix6sQ+NZ57P58pfoheNHNDrJRrPPJ9FL/ZhwoS4IxQREZF8paQtx0aOhKuuLWX3z5TRRBFnfLeMq64tVQubiIiIpKWkLSavvho8f/JJrGGIiIhIgVDSFoPNm+Hjj4PXStpEREQkE0raYrByJSSmfFXSJiIiIplQ0haDurrg+VOfgv/6r3hjERERkcLQI+4AuqPSUjjhBJg6FfbbL+5oREREpBAoaYvBbrvBrFlxRyEiIiKFRJdHY5C4n+3yy2G77eKNRURERAqDkrYYXHopbL89mAUdERo0R7yIiIi0QUlbDJYvDxK27bcP3qsHqYiIiLRFSVsM6upg4ECorAzeK2kTERGRtihpi0FdHQwYABUVwXslbSIiItIWJW0xSCRtI0fCmWeqM4KIiIi0TUN+xOD442GXXWCPPeCGG+KORkRERAqBkrYYXHJJ8+umJtiyBUpKYgtHRERECoAuj+bYli2wfn3wev166NEDrroq3phEREQk/ylpy7F//xv69AlmROjdO0ja1BFBRERE2qKkLccSk8X37x+M1VZZqaRNRERE2hZp0mZm483sX2ZWY2ZTU6wvNbNZ4fqnzGxYuLzEzG4zs5fM7DUzm5bpNvPd8uXB84ABwXNFBaxeHV88IiIiUhgiS9rMrBiYAUwA9gRONrM9WxQ7HVjl7rsCVwO/CpcfD5S6+97A/sBZZjYsw23mtURLWyJpU0ubiIiIZCLK3qOjgRp3fxPAzO4BjgFeTSpzDHBJ+Po+4FozM8CBPmbWA+gNbATWZLjNvJZI2qqqgudvfQtKS+OLR0RERApDlEnbYODdpPfvAQe2VsbdN5vZaqA/QQJ3DPABUAZMcfePzSyTbQJgZmcCZwIMHTq00zuTLQcfDBdfDD17Bu8nT443HhERESkM+TpO22hgC7ATsB3wuJk93J4NuPuNwI0A1dXVnvUIO+iww4JHQmNjcE/bwIHxxSQiIiL5L8qOCMuAnZPeDwmXpSwTXgqtAFYCE4G/ufsmd18O/BOoznCbeW3ZMlizpvn9T34Cw4fHF4+IiIgUhiiTtmeA3cxsuJn1BE4CZrcoMxv4Zvj6OOARd3dgKXAYgJn1AcYAr2e4zbw2fjycemrz+8rKYJDdjRtjC0lEREQKQGRJm7tvBs4D5gGvAfe6+ytmdpmZHR0Wuxnob2Y1wPeBxBAeM4C+ZvYKQaJ2q7u/2No2o9qHKNTVbX0ptLIyeNawHyIiIpJOpPe0ufscYE6LZRcnvW4gGN6jZb36VMtb22ahaGqCFSuah/uAYJw2CIb9SF4uIiIikkwzIuTQJ58Ec48mJ2eJljaN1SYiIiLpKGnLoZYD6wLstRf88pew447xxCQiIiKFIV+H/OiS+veH6dNh9OjmZcOHw9SCm4xLREREck1JWw5VVcH552+9rKkJ3nkHysuDpE5EREQkFV0ezaEPPoBXXgnua0tYvx5GjIBbb40vLhEREcl/Stpy6OabYdQo2Ly5eVmfPlBcrI4IIiIikp6Sthyqq4N+/baeIN4s6EGqpE1ERETSUdKWQ3V1qcdiq6hQ0iYiIiLpKWnLoZazISSopU1ERETaot6jOVRXB0OHbrv8Rz+CsrLcxyMiIiKFQ0lbDl1xBfTqte3yr38997GIiIhIYVHSlkPjx6devmxZMBxIdXVu4xEREZHCoXvacqSxER56CD76aNt1V10Fn/987mMSERGRwqGkLUfefRe+9KUgcWupogLq67cev01EREQkmZK2HEk1WXxCZWXwvHp1zsIRERGRAqOkLUcySdo07IeIiIi0RklbjixfHjy3NrguKGkTERGR1ilpy5F0LW0HHACzZsGwYTkNSURERAqIhvzIkZNPhn32gd69t123005wwgm5j0lEREQKh5K2HBk2rPWWtI0b4YknYMQItbaJiIhIaro8miMPPRQkZqls2ACHHw5//nNuYxIREZHCoZa2HJk6FXbcEf76123X9esHZuqIICIiIq1TS1uO1NXBwIGp1xUVBT1IlbSJiIhIa5S05YB7kLSl6jmaUFmppE1ERERap6QtB+rrg7lH0yVtFRWaEUFERERap3vaciDdGG0JM2ZA3765iUdEREQKj5K2HBg8GJ57DoYMab3M5z6Xu3hERESk8OjyaA6UlsJ++6VvaXvhBbj//tzFJCIiIoVFSVsOvPAC3HBDMB5ba269FU47LWchiYiISIFR0pYD8+bB2WdDU1PrZSorYe3a9GVERESk+1LSlgPLlwdzjvbp03qZyspgaJA1a3IWloiIiBSQSJM2MxtvZv8ysxozm5pifamZzQrXP2Vmw8Llp5jZkqRHk5ntG66bH24zsa6VIWvzR1tjtEGQtIHGahMREZHUIkvazKwYmAFMAPYETjazPVsUOx1Y5e67AlcDvwJw97vcfV933xeYBLzl7kuS6p2SWO/uy6Pah2zJJGmrqAielbSJiIhIKlG2tI0Gatz9TXffCNwDHNOizDHAbeHr+4DDzcxalDk5rFuwMknaxo6FZ56B3XfPTUwiIiJSWKIcp20w8G7S+/eAA1sr4+6bzWw10B9YkVTmRLZN9m41sy3An4DL3d2zGXi2zZ0bzIiQzvbbBw8RERGRVPK6I4KZHQisd/eXkxaf4u57A4eEj0mt1D3TzBab2eK6xJQEMamqCgbYTWf9epg5E15+OX05ERER6Z6iTNqWATsnvR8SLktZxsx6ABXAyqT1JwF/TK7g7svC57XA3QSXYbfh7je6e7W7Vw9o69pkhDZsgIsvhmefTV+usRHOOAMefjg3cYmIiEhhiTJpewbYzcyGm1lPggRsdosys4Fvhq+PAx5JXOo0syLgBJLuZzOzHmZWFb4uAY4C8rpt6qOP4Oc/DwbYTae8PHjWpPEiIiKSSmT3tIX3qJ0HzAOKgVvc/RUzuwxY7O6zgZuBO8ysBviYILFLOBR4193fTFpWCswLE7Zi4GHgpqj2IRsymSweoLg4SNzUe1RERERSiXTCeHefA8xpsezipNcNwPGt1J0PjGmxbB2wf9YDjVCmSRsEY7UpaRMREZFU8rojQlegpE1ERESyIdKWNoEV4eAlmSRtDzyQfqorERER6b7U0hax738fVq2Cfv3aLjt8OAzM+0m5REREJA5K2iJmFlz23GaehxT+/neYPj3ykERERKQAKWmL2PTp8LvfZVb2L3+Bn/0s2nhERESkMClpi9hddwXJWCYqKmDNGmhqijYmERERKTxK2iKWyWTxCZWVQcJWXx9pSCIiIlKAlLRFrK4u884FlZXBs4b9EBERkZaUtEWooSFoNWtPSxsoaRMREZFtaZy2CH38MZSVZZ60HXlkMK5bInkTERERSVDSFqGddoJ16zLvWNC7d/AQERERaUmXR3OgKMOj/Mkn8KMfwaJFkYYjIiIiBUhJW4QeeQQmTWqeyqotmzfDL38JTz8dbVwiIiJSeJS0ReiFF+DOO6FHhhehKyqC59Wro4tJRERECpOStggtXw4lJc3JWFtKSoIJ49V7VERERFpS0hahujqoqsps3tGEykolbSIiIrItJW0Ras9sCAmVlbB2bSThiIiISAHTkB8R6tULRo5sX51nn4WePaOJR0RERAqXkrYIzZrV/jqlpdmPQ0RERAqfLo/mmTvvhB/+MO4oREREJN8oaYvIxo1w2GHwpz+1r96TT8Itt0QTk4iIiBQuJW0RqauDRx/NfGDdhETvUfcoohIREZFCpaQtInV1wXNHeo9u2QLr12c9JBERESlgStoi0pmkDTRWm4iIiGxNSVtEOpq0bbcdlJdDfX32YxIREZHCpaQtIj17wl57wcCB7at33HHB3KN77BFNXCIiIlKYlLRF5Ljj4OWXYfvt445EREREugIlbXlm+XI46aSg56mIiIhIgpK2iHz3u/DNb3as7qxZ8Oqr2Y1HRERECpumsYrIc891bA7RiorgWb1HRUREJJla2iJSV9f+nqMQzD3au3fQGUFEREQkQUlbRDqatEHzrAgiIiIiCZEmbWY23sz+ZWY1ZjY1xfpSM5sVrn/KzIaFy08xsyVJjyYz2zdct7+ZvRTWmW5mFuU+dMSmTbBqVceTtpEjoVev7MYkIiIihS2ye9rMrBiYAXwReA94xsxmu3vyLfanA6vcfVczOwn4FXCiu98F3BVuZ2/gAXdfEta5HjgDeAqYA4wH5ka1Hx2xYQMccQTsuWfH6j/+eHbjERERkcIXZUvbaKDG3d90943APcAxLcocA9wWvr4PODxFy9nJYV3MbEeg3N0XubsDtwPHRhR/h5WXw7x5cPzxcUciIiIiXUWUSdtg4N2k9++Fy1KWcffNwGqgf4syJwJ/TCr/XhvbBMDMzjSzxWa2uC4xp1SB+O1v4RvfiDsKERERySd53RHBzA4E1rv7y+2t6+43unu1u1cP6OjNZR305z/D8OHw1lsdq19TAw89lN2YREREpLBFmbQtA3ZOej8kXJayjJn1ACqAlUnrT6K5lS1Rfkgb24zdsmXw9tvQt2/H6id6j7pnMSgREREpaFEmbc8Au5nZcDPrSZCAzW5RZjaQmDfgOOCR8F41zKwIOIHwfjYAd/8AWGNmY8J7304FHoxwHzqkrg7MOj7vaEVF0AN1w4bsxiUiIiKFK7KkLbxH7TxgHvAacK+7v2Jml5nZ0WGxm4H+ZlYDfB9IHhbkUOBdd3+zxaYnAzOBGqCWPOs5CsH8of37Q3Fxx+pXVgbPGmBXREREEiKdxsrd5xAMy5G87OKk1w1Ayj6W7j4fGJNi+WJgVFYDzbLODKwLMGQI7LsvbNyYtZBERESkwGnu0QgccADstlvH6x91VPAQERERSVDSFoGp28z9ICIiItI5eT3kR6HqbK/Pd9+FAw+Ev/41O/GIiIhI4VPSlmVbtkBZGfz61x3fRo8e8PTTsHRp9uISERGRwqakLctWroSGBujdu+PbUO9RERERaUlJW5YlZswaOLDj2+jVC3r2DAbYFREREQElbVmXSNo6M+SHWfOsCCIiIiKgpC3rspG0AYwbB8OGdTYaERER6So05EeWDR0KZ50Fgwd3bjuzZmUnHhEREekalLRl2YEHBg8RERGRbNLl0Sxbvz4Y9qOzLroIDjus89sRERGRrqHNpM0C3zCzi8P3Q81sdPShFabTToO99+78dtasgdde6/x2REREpGvIpKXtOuAg4OTw/VpgRmQRFbi6Oujfv/PbUe9RERERSZZJ0nagu58LNAC4+yqgZ6RRFbC6us73HIUgaWtogMbGzm9LRERECl8mSdsmMysGHMDMBgBNkUZVwLKZtIFmRRAREZFAJknbdOB+YKCZ/QJ4AvhlpFEVqKamYBqrzsyGkLDHHvDVr3Z+8nkRERHpGtoc8sPd7zKzZ4HDAQOOdXfdIp/C5s1w8cUwdmznt3X44cFDREREBDJI2szsDnefBLyeYpkk6dkzSNpEREREsi2Ty6N7Jb8J72/bP5pwCtu6dfD++9kZp+2NN4J74/70p85vS0RERApfq0mbmU0zs7XAPma2xszWhu+XAw/mLMIC8re/BdNXvfRS57dVVgYrVgT3yImIiIi0mrS5+y/dvR9wpbuXu3u/8NHf3aflMMaCkZgsPhsdERK9RzVWm4iIiEBmHRGmmdl2wG5Ar6Tlj0UZWCFKJG1VVZ3fVlkZ9OihpE1EREQCmXRE+A5wATAEWAKMAZ4ENDNmC3V1UFERdEjoLLOgtU3jtImIiAhk1hHhAuAA4B13/zywH/BJlEEVquXLszOwbsI3vgHV1dnbnoiIiBSuNlvagAZ3bzAzzKzU3V83sz0ij6wAnXYafPnL2dve1Vdnb1siIiJS2DJJ2t4zs0rgAeDvZrYKeCfKoArV+PHZ32ZTExRl0h4qIiIiXVomHRG+Gr68xMweBSqAuZFGVaCefx6GDMneJdJTToElS+CVV7KzPRERESlc7WrDcfcFQAMwJ5pwCpc7jB6d3UuavXur96iIiIgE0g2ue5iZ/dvM6s3sTjPb28wWE0wWf33uQiwMn3wSzD2azY4IlZVK2kRERCSQrqXtt8CZQH/gPoJhPv7g7vu7+59zEVwhSYzRls2kraIC1q+HjRuzt00REREpTOmSNnf3+e7e6O4PAMvc/docxVVwsjkbQkJiVgSN1SYiIiLpOiJUmtnXkssmv8+ktc3MxgPXAMXATHe/osX6UuB2ggnoVwInuvvb4bp9gBuAcqAJOCAcemQ+sCOwIdzMEe6+vK1YohZFS1t1NVx4YTAzgoiIiHRv6dKBBcBXkt4/lvTegbRJm5kVAzOALwLvAc+Y2Wx3fzWp2OnAKnff1cxOAn4FnGhmPYA7gUnu/oKZ9Qc2JdU7xd0Xt717ubP//nD77TByZPa2edBBwUNERESk1aTN3b/VyW2PBmrc/U0AM7sHOAZITtqOAS4JX98HXGtmBhwBvOjuL4SxrOxkLJHbeWeYNCm723SH+vpgWqzS0uxuW0RERApLlMO2DgbeTXr/XrgsZRl33wysJuj4sDvgZjbPzJ4zsx+2qHermS0xs5+GSV7sXnoJnnoq+9ssL4e//CW72xUREZHCk69j7fcADgZOCZ+/amaHh+tOcfe9gUPCR8r2LTM708wWm9niusQNZxG64gqYODG720x0RNCwHyIiIpI2aTOzIjP7rw5uexmwc9L7IeGylGXC+9gqCDokvAc85u4r3H09wWC+nwVw92Xh81rgboLLsNtw9xvdvdrdqwdks3dAK+rqstsJAdR7VERERJqlTdrcvYmgM0FHPAPsZmbDzawncBIwu0WZ2cA3w9fHAY+4uwPzgL3NrCxM5sYCr5pZDzOrAjCzEuAo4OUOxpdVUSRtffsG846qpU1EREQyuTz6DzP7envvHQvvUTuPIAF7DbjX3V8xs8vM7Oiw2M1AfzOrAb4PTA3rrgKuIkj8lgDPuftfgVJgnpm9GC5fBtzUnriisnx59pO2oqJggF0lbSIiIpLJCGBnESRUW8xsA2AEA++Wt1XR3efQYp5Sd7846XUDcHwrde8kGPYjedk6gjHd8op7NC1tAD/+MXz609nfroiIiBSWNpM2d++Xi0AKmTv87W8wuGXf2Cy48MLsb1NEREQKT0Zj7YeXMw8N38539/+LLqTCU1QEhx0WzbZXrYJ162DIkGi2LyIiIoWhzXvazOwK4AKCQXFfBS4ws19GHVgh+eADmDULVkYwBPC3vw1HHpn97YqIiEhhyaQjwpHAF939Fne/BRgPfDnasApDbS1MmdzIqJEbOPmkJvbYZQNTJjdSW5u9z6is7LodERLHb1D5BoqLmhhUnv3jJyIi0lVkOrhuZdLrigjiKDhz58KYfdbRe+Z0nt4wio305Kl1o+g9czpj9lnH3LnZ+ZyumrQlH7+Fa0fR6D1ZuDb7x09ERKSrsGBYtDQFmidyf5Sg5+ihwFR3nxV9eNlRXV3tixdnb3752tog4Zi9/gscxKJt1j/JGI4ue5hFL/bp9ATyl14Kl1wCmzZBj4zuQMx/uTx+IiIihcbMnnX36pbL25wRAWgCxgB/Bv4EHFRICVsUrv1tI2dsui5lwgFwEIv4zqbrmXF1Y6c/KzErwpo1nd5U3sjl8RMREekqMmlpW5wq2ysk2W5pG1S+gYVrRzGSN1stU8sIPlf+Eh+uLuvUZ734Ijz+OJx2GvTp06lN5Y1cHj8REZFC01pLWyZJ2xXACmAWsC6x3N0/znaQUcl20lZc1ESj96QHW1ots4ke9C5qZPOWTG8b7D50/ERERFrXocujoROBc4HHgGfDR/YyoAJU1beRd9glbZmlDKWqb0OnP6uhIWht60qdEXJ5/ERERLqKTO5pm+ruw1s8RuQovrw08RtF3FxydtoyM0vOYeKk4k5/1uuvw2c+A48+2ulN5Y1cHj8REZGuIm3S5u5NwA9yFEvBOO/CUm4qmcyTjEm5/knGMLPkHM6dUtrpz0p0ROhKLW25PH4iIiJdRSaXRx82s4vMbGcz2z7xiDyyPDZyJNx+Xx+OLnuYaSVXUssINtGDWkYwreRKji57mNvvy85wFV0xaUs+fj8o2vr4Tc3y8RMREekqdE9bB02YAIte7EPjmefzufKX6F3UyOfKX6LxzPNZ9GIfJkzIzueUl4NZ10raoPn4bTknPH7WyN68xNtfzu7xExER6SraHK7V3YfnIpBCNHIkXHVtKVddm1iS/eEpioqCxK2rJW2w9fFbtQr69y9jz/1QC5uIiEgKrba0mdkPk14f32Ldf0cZlGzthhtg0qS4o8i+m2+GL30J1q2D7bYLOlwsWBB3VCIiIvkp3eXRk5JeT2uxbnwEsUgrTjwRqgt6eOPU5s6Ff/2redDgM86AL3wh3phERETyVbrLo9bK61TvJUKvvgr19TB6dNyRZI970Kp25JHNyyZPji8eERGRfJcuafNWXqd6LxGaNg3eeQeWLIk7kux59VVYsQLGjdt6eX091NXBcN1JKSIispV0SdtnzGwNQata7/A14ftekUcm/1FZCS+8EHcU2ZW4d23s2K2XH3oo9O8Pf/977mMSERHJZ60mbe6u4ejzRGVl1+s9OmAAfP3r27aoHXwwzJwJGzdCz57xxCYiIpKPNBt3AaiogDVroKkp7kiy5/jj4b77gjHoko0dCxs2wOJuPxKgiIjI1pS0FYDKyuDG/TVr2ixaEOrrg0cqhx4aPGvoDxERka0paSsAxx4Lc+ZA795xR5Idd90VjMv23nvbrhswAPbaC+bPz3lYIiIiea3NGREkfiNGBI+uYv58GDgQBg9Ovf6aa4LOCCIiItJMSVsBWLUKHnsMDjwQdtgh7mg6JzE+2+c/v+39bAmHH57bmERERAqBLo8WgLfeCi6RPvVU3JF03htvwAcfbDvURzL3oJOChv0QERFpppa2AlBRETx3hWE/WhufLZkZXHwxDBsGX/xiTsISERHJe2ppKwCVlcHz6tWxhpEVn/88/O53sPvu6cuNHQtPPAGbN+cmLhERkXynpK0AdKWWtl13hfPOa/1+toRx42DtWnj++ZyEJSIikveUtBWAHj2gb9/CT9o++AD+93+DZKwticunGq9NJD/V1sKUyY0MKt9AcVETg8o3MGVyI7W1cUcm0nUpaSsQ8+bBBRfEHUXnzJkDJ5yQeny2lnbYAfbYo+vNuSrSFcydC2P2WUfvmdNZuHYUjd6ThWtH0XvmdMbss465c+OOUKRrMnePbuNm44FrgGJgprtf0WJ9KXA7sD+wEjjR3d8O1+0D3ACUA03AAe7eYGb7A38AegNzgAu8jZ2orq72xZoXKXaTJsFDD8GHH7Z9eRRg5UrYfvvMyopIbtTWBgnb7PVf4CAWbbP+ScZwdNnDLHqxDyNHxhCgSBdgZs+6e3XL5ZG1tJlZMTADmADsCZxsZnu2KHY6sMrddwWuBn4V1u0B3Amc7e57AeOATWGd64EzgN3Cx/io9iGfPPwwzJ4ddxQdlxif7dBDM0/C+vdXwiaSb679bSNnbLouZcIGcBCL+M6m65lxdWOOIxPp+qK8PDoaqHH3N919I3APcEyLMscAt4Wv7wMONzMDjgBedPcXANx9pbtvMbMdgXJ3XxS2rt0OHBvhPuSNa66BSy+NO4qOe/ttePfdoINBpjZuDFrnbr01qqhEpL3uvrOJ0zf9Pm2Z72y6nrvv2JKjiES6jyiTtsHAu0nv3wuXpSzj7puB1UB/YHfAzWyemT1nZj9MKp98R1SqbQJgZmea2WIzW1xXV9fpnYlbRUVhd0RYuDB4Tjc+W0s9e8KiRfDAA5GEJCIdsKK+lF14J22ZoSxlRX2vHEUk0n3ka0eEHsDBwCnh81fNrF2TG7n7je5e7e7VAwYMiCLGnKqsLOykbeLEYDaEPVteIG/D2LHw+OPQ1BRNXCLSPlV9G3mHXdKWWcpQqvo25Cgike4jyqRtGbBz0vsh4bKUZcL72CoIOiS8Bzzm7ivcfT1Bh4PPhuWHtLHNLimRtEXYbyRSZsEYbUXtPOPGjQvmXn3xxUjCEpF2mviNIm4uOTttmZkl5zBxUnGOIhLpPqJM2p4BdjOz4WbWEzgJaHkr/Wzgm+Hr44BHwnvV5gF7m1lZmMyNBV519w+ANWY2Jrz37VTgwQj3IW9UVgatTfX1cUfSfu++G9yb9sor7a+r8dpE8st5F5ZyU8lknmRMyvVPMoaZJedw7pTSHEcm0vVFlrSF96idR5CAvQbc6+6vmNllZnZ0WOxmoL+Z1QDfB6aGdVcBVxEkfkuA59z9r2GdycBMoAaoBbrFiEDf/Ca8/jqUlcUdSfs9+ijceSds6cB9yTvvDF/6EvTunf24RKT9Ro6E2+/rw9FlD/P/elxJLSPYRA9qGcGFXMmRPR/m9vs03IdIFCIdpy1faJy2eH372/Dgg1BX1/7LoyKSn2prYcbVjdx9xxZW1Peiqm8DvfsWU7+xlKVL9Y+WSGfkfJw2ya7334errgqGzig0ifHZOpOwbdkCDbqvWSRvjBgBl/x3KR+uLmPzliI+XF3GrXeVsmIFzJwZd3QiXZOStgLx/vtw4YXw8stxR9I+770Hb77ZvqE+WlqxAqqq4KabsheXiHTOG2/AdtvBffc1Lxs3LvgH7YYbCrfTlEg+U9JWICorg+dCG/bj/ffh059u36C6LVVVBePUqTOCSP5YsCDoHLX33lsvv+UW+Oc/NZuJSBR6xB2AZKaiIngutKRt9Gh49dXOb2fs2GDCeXf9MRDJB/Pnww47wO67b7080QGhqSl49NBfGZGsUUtbgSjUpC1bg+KOGxdcJs1GAiginZOYS3js2NT/RK1cCfvtp3vbRLJNSVuB6NkzGO6jkJK2998PJn2///7ObytxT9z8+Z3floh0Tm0tLFvW+r2q228PffrAL38ZzCEsItmhpK2A/OtfhTVp/IIFQZI5dGjntzV8OPz853DQQZ3floh0TmUlTJ8OEyakXm8GP/sZLF0Kt92W09BEujSN0yaROessuOce+PhjKNaMNiLdijuMGQPLl8O//w0lJXFHJFI4NE5bF3D77XDjjXFHkbkFC+CQQ7KXsG3cGGzzww+zsz0RaT/3YJiPjz5KXy7R2vb22zBrVk5CE+nylLQVkHvuKZyxyj78MLic25nx2VpaujTokPDAA9nbpoi0z9tvw/HHbz0+W2smTIA//QlOPDHysES6BSVtBaSysnA6IrjD1Klw5JHZ2+bIkbDTThqvTSROie9fJv+QmcHXvqZLoyLZoqStgBRS0rbjjkHPsb32yt42zYKWtvnzNdq6SFzmzw8GvN5zz8zr3HtvcKvE5s2RhSXSLShpKyCJpK0QEpannopmrtCxY4NLr2+8kf1ti0jbOjKXcGkpPPEE3HVXdHGJdAdK2gpIRUXwn+r69XFHkt7y5UGvsWuuyf62NV6bSHzefTe4p62996oefTR85jPwi1+otU2kM5S0FZALLghar/r0iTuS9B57LHjOZieEhN13hyefhNNOy/62RSS9nXeGt96CiRPbV88MLr44aCG/555oYhPpDpS0FZBevYLLDPlu/vwgsdx//+xv2yxoxevZM/vbFpG2DRsW3NPWXsceG0wu//Ofw5Yt2Y5KpHtQ0lYgamvh26c0UtFzA8VFTQwq38CUyY3U1qavM2VyI4PKo63Tst51M5qwhg388IK263XEggUwet9GBvaLfr9E4pKN72K2z/Xzz4d58zpWt6gouGXiRz+CC8/Xd1GkI5S0FYC5c2HMPusYeO90nts0ikbvycK1o+g9czpj9lnH3Lmt1+k9czoL10ZXJ1W9jfRkyZa263X0WHx9/DoOfWE6T9ZHu18iccnWdzGb5/q778K118Jrr3V8Gw0NcNHkdZTpuyjSMe7e5R/777+/F6qaGveqsnpfyBj3oOPoVo+FjPGqsnqvqcl9nc7Uy+djIRKnfP0u3nFHsKnnnsvtfol0R8BiT5HPqKUtz13720bO2HQdB7Eo5fqDWMR3Nl3PjKsbc16nM/U6Ipf7JRKXfP0uLlgQDDu0zz4dqq7vokg2pMrkutqjkFvaBvZb7zWMSPmfaeJRwwgvL1nnp5zifsop7tv1yqzOwH7Ndfr1yPxz5s0LYlu6NPN6g8rXxXIsqvrkLj6RbMj0PE+cs5dd1r7vcEfP9d12c//KV3K3XyLdGa20tPWIO2mU9FbUl7IL76QtM5Sl1G/qxaLwH9jVDZnVWVnfXKd+c+afk5iwff36zOutqO+VtkwmOnIsPl6fu/hEsiHT8zxxzr76KjzzTLTfxXXroHdv+Pzn2131P9q7XyKyLV0ezXNVfRt5h13SllnKUAaUN1BTAzU1UNUvszpV/ZrrDMiwzoDyBk49NXi/xx6Z16vq2/npETp0LDKsk434RLKhvefsH//Yvu9wR871Pn3ghRfge99rd9X/0HdRpPOUtOW5id8o4uaSs9OWmVlyDhMnFee8TmfqdUQu90skLvn4XXQPns3aXfU/9F0UyYJU10y72qOQ72lT79F49kskLvn4XTzgAPef/Sye/RLpjmjlnrbYE6pcPAo5aXN3nzMn+GU3teRKr2GEb6SH1zDCp5Zc6VVl9T5nTnx1OlMvn4+FSJwS5+wPirLzXbyQjp/r778f/KX49a87t0/p4ruoSN9FkWRK2gpcTY37lHMbfFD5Oi8u2uKDytf5lHMb0v5Xmqs6nanXEZ3eL9vi2/da5xecE018ItlQU+O+69AG71PUue/idr3WeQkNfscdHYvjnnuCvxRPP92x+m3Ft33vIL4bbsjO9kW6gtaSNgvWdW3V1dW+ePHiuMOQPHHvvXDiifDUUzB6dNzRiKS2eTNstx1MmgTXXdfx7TQ0wC9+AeedB4MGtb/+5Mlw553w8cfQI4LxBjZtgk99KtjXZ57p3H1zIl2FmT3r7tUtl6sjgnQ7hx4aPM+fH2sYImk9/zzU18PYsZ3bTq9ewSTtHUnYIBhU9+CDo0nYAEpKgvlIn30W5syJ5jNEugolbdLt7LBD8J/9ggVxRyLSurfegr59O5+0JSxYABde2L46TU3wta8FrX1ROvVUGDYMLr20uaeqiGxLSZt0S2PHwuOPB5egRPLRCSfAqlXBPxnZ8NxzcNVVwXmfqaKioJXu5JOzE0NrSkqChO3QQ2Hjxmg/S6SQRZq0mdl4M/uXmdWY2dQU60vNbFa4/ikzGxYuH2ZmG8xsSfj4fVKd+eE2E+sGRrkP0jWNGwdr1wajyYvkq2xekjzrLBg4EC67LPM6//53MBtCLpx6KvzmN1BampvPEylEkSVtZlYMzAAmAHsCJ5vZni2KnQ6scvddgauBXyWtq3X3fcNHyxEZT0latzyqfZCu66ij4KOPOj75tUiUnn8e9t03uM8rW8rK4Ac/gIcfhoULM6vz9a/DccdlL4a2uMPf/85/pqETka1F2dI2Gqhx9zfdfSNwD3BMizLHALeFr+8DDjdT3yGJXt++QauDSD569NFg2qhsXRpNOOccGDAguBTZlhUr4OWX4ZBDshtDOps2wemnB/fe6d42kW1FmbQNBt5Nev9euCxlGXffDKwG+ofrhpvZ82a2wMxa/tq4Nbw0+lMledJRf/97MPTHli1xRyKytfnzYdddYXDL35id1KcPXH45jB/fdlL02GPB87hx2Y0hnZ49Ydq0oCXwH//I3eeKFIp87YjwATDU3fcDvg/cbWbl4bpT3H1v4JDwkbJfk5mdaWaLzWxxXV1dToKWwrJ8eTBm24svxh2JSLMtW4LOAtnqNdrSmWfClCltj4c2fz707g3V24wUFa1vfztIVtWTVGRbUSZty4Cdk94PCZelLGNmPYAKYKW7N7r7SgB3fxaoBXYP3y8Ln9cCdxNcht2Gu9/o7tXuXj1gwICs7ZR0HYk/ihqvTfLJSy/BJ59E28K1aRPcemtw71xrFiyAz30uaP3KpdJSmDoVnnhC302RlqJM2p4BdjOz4WbWEzgJmN2izGzgm+Hr44BH3N3NbEDYkQEzGwHsBrxpZj3MrCpcXgIcBbwc4T5IFzZkCIwcqfHaJL8UFQXDfUSZtDU0wEUXwU9/2nqZm28OhvuIw3e+E7TwrVoVz+eL5KuIxrgO7lEzs/OAeUAxcIu7v2JmlxHMqTUbuBm4w8xqgI8JEjuAQ4HLzGwT0ASc7e4fm1kfYF6YsBUDDwM3RbUP0vWNHQv33x8MIlqUrzcLSLeyzz4wa1a0n9GvH3z/+/CTn8Dixakvgeb6smiyXr3g6ac1pZVIS5p7VLq1P/4Rpk+HBx7o+DQ/ItnS1ATLlsHOO7ddtrPWrAlmITjkEHjwwa3X3X9/MEbcV74SfRzpbNoE8+YFQ/SIdCeae1QkhZNPhiefVMIm+eGVV2Do0KCDTNTKy4MOCbNnb3tv289/DldfHX0Mbbn55iBxfOKJuCMRyQ9K2kTQsB+SHxI33h94YG4+77vfDVrakmc9WLUKliyJrvdqe5x6avAPVSbjyol0B0rapNu74grYZZfg0pRInBYsCM7FXXbJzedVVATjsR18cPOyJ54IhtrI5fhsrenILA4iXZmSNun2dtwxuI9I85B2L7W1MGVyI4PKN1Bc1MSg8g1MmdxIbW009driHiRtcSRLS5bAV74U7NOxRzfRmw3cd3fn9ykbzj4btt8eTj2pfcc8qp+TSJyUtEm3p/Haup+5c2HMPuvoPXM6C9eOotF7snDtKHrPnM6YfdYxd25262Xi1VeDqaNyfVly7lwYN3odezwU7hM9eYlR9Lu18/uUDY89BlvWruOr72Z+zKP8OYnEyt27/GP//fd3kXSGDnU/7ri4o5BcqKlxryqr94WMcQ8auLZ6LGSMV5XVe01NduplatUq9zvvdH///U7vYsai3qc44sv3fRLJBMHQaNvkM2ppEyFo3ViwQNPmdAfX/raRMzZdx0EsSrn+IBbxnU3XM+PqxqzUy1RlJZxySnC5Plei3qfO6kh8+b5PIp2hcdpEgIcegueeC4ZAKC2NOxqJ0qDyDSxcO4qRvNlqmVpGsF+Plzjsy2UAfO97cOLRmdX7XPlLfLi6rF0xucONN8KXvhSMnZYrmR6LjuxTNrQnvudfL+Occ+CRv27g+c35u08imdA4bSJpHHFEMN+hEraub0V9KbvwTtoyQ1nKus29ePttePttqK/PvN6K+l7tjun114Mb7v/xj3ZX7ZQo9ykb2hPf5s3hz2pzfu+TSGcoaRMJrVoVTOkjXVtV30beIf2YGksZyoDyBpYsCXpWHnVU5vWq+ja0O6ZEJ5hcd0KIcp+yoT3x7bxz8LMa0C+/90mkM5S0iYTOPx++/GXd19bVTfxGETeXnJ22zMySc5g4qTgr9TKxYAHstBOMHNnuqp0S5T5lQ0fiy/d9EumUVL0TutpDvUclEzfdFHQwe+21uCORKOVb79GmJvcddnCfODF7+5ipfO9pqd6j0l2h3qMi6SUuTS1YEG8cEq2RI+H2+/owocfDXMiV1DKCTfSglhFMK7mSo8se5vb7+mzT6pWod3TZw0wr2breD4par9eWd96Bjz6KZ9qodPuU7ljkc3zp6lzIlUwoiXefRDpDvUdFQu4weHDwx/OPf4w7GolaTQ1ccVkj//fgFlbU96KqbwMTJxVz7pTStH/Qa2thxtWN3H1HUK+8ZwP1DcXcOauUE07oWCyffALFxdCvX8fqd1bLfcr0WORzfKnqVA0s5q33S3n//WAKL5F81VrvUSVtIkkmTgxuCl+2DMzijkaismYNlJdnZ1vr1sHw4bDffjBvXna2KdF44w344AM49NC4IxFJT0N+iGTgxz8OJqeWruvFF4Ob/v/2t+xsr0+fYFLzhx6CRanHc22VO5x8MjzwQHZikfR2200JmxQ2JW0iSfbaC/bcU61sXdnPfw5FRTB6dPa2ec45UFUFl13Wvnq1tXDPPfDhh9mLRdJragp6il9+edyRiLSfkjaRFu6/H266Ke4oJAovvwz33Qff/S5sv332ttu3L1x6KRxySJAUZCrR6SWOTgjdVVERvP8+XHllMDajSCFR0ibSwj33BH+Au8Htnt3O5ZcHCdaUKdnf9uTJMG1akBRkav58GDgQPvWp7Mcjrbv44uC+xmuuiTsSkfZR0ibSwtixQUeEN1ufulAK0LJlQSvb+edD//7RfMaWLUHS/8ILbZd1D1raxo7V5fhc+8xn4Nhj4X/+B1avjjsakcwpaRNpYdy44FnjtXUtgwcH0xxdeGF0n7FuXdDi9tOftl22vj4YU+yII6KLR1p38cVBwjZ9etyRiGROSZtIC5/+NAwY0DwfpBS+xH1mo0ZF18oGwTAiU6bAX/4Czz2Xvmy/fvDoo/Cd70QXj7Ruv/2Cy6MnnRR3JCKZU9Im0oJZMCzA0qVxRyLZctppcPrpufms734XKivb7km6aVNOwpE0vvvdYBgQkUKhpE0khTvvVEtbV/Hvf8Ndd2W3t2g6FRXwve/Bgw8Gl2Nbs+eeMHVqbmKS1r32GpxyCqxdG3ckIm1T0iaSQq9ecUcg2fKLX0BpKVx0Ue4+84IL4IADgumpUnn77WAarcGDcxeTpFZfD3ffDddeG3ckIm1T0ibSirPOivamdYleTU3Qynb22TBoUO4+t7ISnn66uVNLSxqfLX8ccABMmAC//W2QwInkMyVtIq2oq4M//znuKKQzfvUrKCmBH/4wns+vrw8uk7a0YEFwuXbUqNzHJNu6+GJYuRKuuy7uSETSU9Im0opx44LLWOqQULguvzwYN22HHeL5/Kuugq9+FV55ZevlCxYEnV3aMxCvRGfMmGDold/8Jhi2RSRf6VeGSCsSl640XlvhGjQIjjkmvs8/99xgQvmf/7x5WWLuy1z1ZpXMXHopnHlm+6YhE8k1JW0irdh7b9huO/UiLURvvx20lLZs4cq1/v2DBO3ee+HVV4NlRUVB79Kjjoo1NGlhzJigZbZfv7gjEWmdkjaRVrz1Fuy+SyN/vmsDxUVNDCrfwJTJjdTWpq9XWwtTJjcyqLx99aTjWh7zz+y+gaceb2y192Yuff/7QW/kE45pjm9gP50T+cgdbrgBvnJE+76/Hf3Od6Reruoovs7HFwl37/KP/fff30XaY84c96qyep9W8muvYYRvothrGOHTSn7tVWX1PmdOdutJx7V2zH9g+XHM58xxL+9R7xeZzol8N2eOe9+ier+IzH9Wufxdkas6iq/z8XUWsNhT5DORJkvAeOBfQA0wNcX6UmBWuP4pYFi4fBiwAVgSPn6fVGd/4KWwznTA2opDSZu0R01N8CVdyJjgK9LisZAxXlVW7zU12aknHZfvxzzf45NmHflZ5fJ3heIrnPiyIedJG1AM1AIjgJ7AC8CeLcpMTiRkwEnALG9O2l5uZbtPA2MAA+YCE9qKRUmbtMf3zmnwaSW/TvklTTymllzpU85tyEo96bh8P+b5Hp8068jPKpe/KxRf4cSXDXEkbQcB85LeTwOmtSgzDzgofN0DWBEmYymTNmBH4PWk9ycDN7QVi5I2aY+B/dZ7DSPSflFrGOGDytf50Ue7f+ELwaNvceb1JDva87NSfJJOpj+rvsXr/vOd3753ZnUG9G2u057fFVV9gvPi8cczr5McX1WfzOps37tj8SXO2xkz2h/fscdmfswrenYuvjPPbH98P/tZvN/f1pK2Hh28FS4Tg4F3k96/BxzYWhl332xmq4H+4brhZvY8sAb4ibs/HpZ/r8U2U04EY2ZnAmcCDB06tHN7It3KivpSduGdtGWGspQV9b1Yvx7Wrw+WrduSeT3Jjvb8rOKQ7/FJs0x/Vuu39PrPd/6ThszqfLyuuQ5k/rti1frgvNiyJfM6yfF9vD6zOqsbOhbfirVBfBs3tj++4uLMj/najR2ML/xeNTS0P77Gxjz9/qbK5LLxAI4DZia9nwRc26LMy8CQpPe1QBXBvW79w2X7EyR25UA18HBS+UOA/2srFrW0SXt09L8rtarkXr4f83yPT5p15GeVy98Viq9w4ssGWmlpi3LIj2XAzknvh4TLUpYxsx5ABbDS3RvdfSWAuz9LkMztHpYf0sY2RTpl4jeKuLnk7LRlZpacw8RJxVmpJx2X78c83+OTZh35WeXyd4XiK5z4IpUqk8vGg+AetTeB4TR3RNirRZlz2bojwr3h6wFAcfh6BEFitn34vmVHhCPbikUtbdIe6j1aOPL9mOd7fNJMvR8VX7fuPRp8JkcC/yZoKftxuOwy4OjwdS/gfwmG73gaGBEu/zrwCsFwH88BX0naZjXBZdVa4Fo05IdEIDE2z9SSK72GEb6RHl7DCJ9acmVGYwe1rHeRpa8nHXfnne5l1PtF1r6fVa509FyS3OvIzyrbvyuy/VmKL574OiuWpC1fHkrapCNqatynnNvgg8rXeXHRFh9Uvs6nnNvQ5n9VLett12udn3BM2/WkY6ZMcS8qcv/WKe3/WeVKR88lyb2O/Kyy9bsiqs9SfPHE1xmtJW0WrOvaqqurffHixXGHISIRePBBWLIEfvazuCMREckOM3vW3atbLtfcoyI5UFcXTBL+Tvre49IBxxyjhE1EugclbSI50NgI118Pv/xl3JF0HXV1cPnlsHp13JGIiOSGkjaRHBgyBE4/HW65BZYujTuaruE3v4GLL4YPPog7EhGR3FDSJpIjU6cGz7/6VbxxdAUrVsCMGXDSSfCpT8UdjYhIbihpE8mRoUPhW9+CmTPhvffaLi+tu+qqYPqwn/407khERHInyrlHRaSFadNgw4ZgZEbpmJUr4Xe/gxNOgE9/Ou5oRERyR0mbSA4NGwa33x53FIVtzRo45BC1solI96PLoyIxeOEF+MMf4o6iMA0fDnPmwF57xR2JiEhuKWkTicE118A556jnY3v95S/w1ltxRyEiEg8lbSIx+PGPYdMmuPLKuCMpHJ98ApMmwQ9+EHckIiLxUNImEoORI+GUU+D3v4ePPoo7msJwzTXBQLo/+UnckYiIxENJm0hMfvKTYKaE3/wm7kjy3+rV8D//E0xZte++cUcjIhIPJW0iMdltNzjrLOjXL+5I8t/vfhdcHr344rgjERGJj4b8EInRddfFHUFhWLMGvv51+Oxn445ERCQ+StpEYuYOc+fC6NFQVRV3NPnp17+Gpqa4oxARiZcuj4rErLYWvvxlOOqIRgaVb6C4qIlB5RuYMrmR2tr09aZMbl+djtbLVZ1U9ar6BPU01IeIdHdK2kRi9sYb0K94HQc/P52Fa0fR6D1ZuHYUvWdOZ8w+65g7d9s6c+fCmH3W0Xtm5nU6Wi9XdVqr99T6UfS6KX09EZFuwd27/GP//fd3kXxUU+NeVVbvCxnjHlwp3eqxkDFeVVbvNTWdq5PLz8plfCIiXRGw2FPkM2ppE4nRtb9t5IxN13EQi1KuP4hFfGfT9cy4urFTdXL5WbmMT0SkO7EgoevaqqurffHixXGHIbKNQeUbWLh2FCN5s9UytYxg3+KXGHVAGUceCdde2b46CS89s4EXtrRd73PlL/H862V87WuZ10l81k9+At8+Ofr4Plxd1moZEZFCZ2bPunt1y+XqPSoSoxX1pezCO2nLDGUp67f0orwcevduf52E9Vsyq7eivhdmUF6eeZ3EZ5WU5CY+EZHuSEmbSIyq+jbyztpd0rYuLWUoA8obmDcvaF268rL21wEYVJ5Zvaq+DeywQxnz5mVeJ/mzOrJP7Y0P1NImIt2P7mkTidHEbxRxc8nZacvMLDmHiZOKO1Unl5+Vy/hERLqVVL0TutpDvUclX+V778x8j09EpCuild6jsSdUuXgoaZN8NmdOkKxMLbnSaxjhG+nhNYzwqSVXelVZvc+Zk506ufysXMYnItLVtJa0qfeoSB6orYUZVzdy9x1bWFHfi6q+DUycVMy5U0oZOTJ7dXL5WbmMT0SkK2mt96iSNhEREZE80lrSpo4IIiIiIgVASZuIiIhIAVDSJiIiIlIAIk3azGy8mf3LzGrMbGqK9aVmNitc/5SZDWuxfqiZ1ZvZRUnL3jazl8xsiZnpRjURERHpFiJL2sysGJgBTAD2BE42sz1bFDsdWOXuuwJXA79qsf4qYG6KzX/e3fdNdZOeiIiISFcUZUvbaKDG3d90943APcAxLcocA9wWvr4PONzMDMDMjgXeAl6JMEYRERGRghBl0jYYeDfp/XvhspRl3H0zsBrob2Z9gf8HXJpiuw48ZGbPmtmZrX24mZ1pZovNbHFdXV0ndkNEREQkfvnaEeES4Gp3r0+x7mB3/yzBZddzzezQVBtw9xvdvdrdqwcMGBBhqCIiIiLR6xHhtpcBOye9HxIuS1XmPTPrAVQAK4EDgePM7NdAJdBkZg3ufq27LwNw9+Vmdj/BZdjH0gXy7LPPrjCzd9oRexWwoh3luyodh2Y6Fs10LJrpWAR0HJrpWDTTsWjW3mOxS6qFUSZtzwC7mdlwguTsJGBiizKzgW8CTwLHAY+Ec24dkihgZpcA9e5+rZn1AYrcfW34+gjgsrYCcfd2NbWZ2WJ1ctBxSKZj0UzHopmORUDHoZmORTMdi2bZOhaRJW3uvtnMzgPmAcXALe7+ipldRjAR6mzgZuAOM6sBPiZI7NIZBNwf9lXoAdzt7n+Lah9ERERE8kWULW24+xxgTotlFye9bgCOb2MblyS9fhP4THajFBEREcl/+doRIW43xh1AntBxaKZj0UzHopmORUDHoZmORTMdi2ZZORYW3EImIiIiIvlMLW0iIiIiBUBJW5K25krtTrrzHK9mdouZLTezl5OWbW9mfzezN8Ln7eKMMVdaORaXmNmy8NxYYmZHxhljLpjZzmb2qJm9amavmNkF4fJud16kORbd8bzoZWZPm9kL4bG4NFw+PJxPuyacX7tn3LFGKc1x+IOZvZV0Tuwbc6g5Y2bFZva8mf1f+D4r54SStlCGc6V2N911jtc/AONbLJsK/MPddwP+Eb7vDv7AtscCgsGv9w0fc1Ks72o2Axe6+57AGIKBvfeke54XrR0L6H7nRSNwmLt/BtgXGG9mYwjm0b46nFd7FcE8211Za8cB4AdJ58SSuAKMwQXAa0nvs3JOKGlrlslcqdINuPtjBEPQJEueJ/c24NhcxhSXVo5Ft+PuH7j7c+HrtQS/jAfTDc+LNMei2/FAYuaekvDhwGEE82lDNzgv0hyHbsnMhgBfBmaG740snRNK2pplMldqd5LRHK/dyCB3/yB8/SHBmIHd2Xlm9mJ4+bTLXxJMZmbDgP2Ap+jm50WLYwHd8LwIL4MtAZYDfwdqgU/C+bShm/wtaXkc3D1xTvwiPCeuNrPS+CLMqf8Bfgg0he/7k6VzQkmbtCajOV67o3DWjm77XyRwPTCS4DLIB8BvY40mh8ysL/An4HvuviZ5XXc7L1Ici255Xrj7Fnffl2CqxtHAp+KNKB4tj4OZjQKmERyPA4Dtgf8XX4S5YWZHAcvd/dkotq+krVkmc6V2G8lzvAKJOV67s4/MbEeA8Hl5zPHExt0/Cn9BNwE30U3ODTMrIUhS7nL3P4eLu+V5kepYdNfzIsHdPwEeBQ4CKi2YTxu62d+SpOMwPryU7u7eCNxK9zgnPgccbWZvE9xmdRhwDVk6J5S0NfvPXKlhr46TCOZG7XbMrI+Z9Uu8Jpjj9eX0tbq8xDy5hM8PxhhLrBJJSuirdINzI7wn5WbgNXe/KmlVtzsvWjsW3fS8GGBmleHr3sAXCe7xe5RgPm3oBudFK8fh9aR/aIzgHq4uf064+zR3H+LuwwjyiEfc/RSydE5ocN0kYRf1/6F5rtRfxBtRPMxsBEHrGjTP8dptjoWZ/REYB1QBHwE/Ax4A7gWGAu8AJ7h7l79Bv5VjMY7gEpgDbwNnJd3X1SWZ2cHA48BLNN+n8iOCe7m61XmR5licTPc7L/YhuKm8mKAR5F53vyz8HXoPwSXB54FvhK1NXVKa4/AIMAAwYAlwdlKHhS7PzMYBF7n7Udk6J5S0iYiIiBQAXR4VERERKQBK2kREREQKgJI2ERERkQKgpE1ERESkAChpExERESkAStpERNrBzOqTXh9pZv82s13ijElEuocebRcREZGWzOxwYDrwJXd/J+54RKTrU9ImItJO4Vy8NwFHuntt3PGISPegwXVFRNrBzDYBa4Fx7v5i3PGISPehe9pERNpnE7AQOD3uQESke1HSJiLSPk3ACcBoM/tR3MGISPehe9pERNrJ3deb2ZeBx83sI3e/Oe6YRKTrU9ImItIB7v6xmY0HHjOzOnefHXdMItK1qSOCiIiISAHQPW0iIiIiBUBJm4iIiEgBUNImIiIiUgCUtImIiIgUACVtIiIiIgVASZuIiIhIAVDSJiIiIlIAlLSJiIiIFID/D8HVEvIGDyBpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:24:18.426827Z",
     "start_time": "2024-01-09T04:24:14.827081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100])})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#... seems like a lot of work... why not...\n",
    "#from sklearn import grid_search\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "k = np.arange(100) + 1\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {'n_neighbors': k}\n",
    "\n",
    "#Note! CV should be no more than 25% of the data!\n",
    "gs = GridSearchCV(    \n",
    "    estimator= knn,\n",
    "    param_grid= params,\n",
    "    cv=5)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "#Check the documentation! How do you get only the best k? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:24:18.473465Z",
     "start_time": "2024-01-09T04:24:18.428878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH K=5\n",
      "\n",
      "\n",
      "[[135   7]\n",
      " [ 10 148]]\n",
      "\n",
      "\n",
      "Confusion Matrix Expanded\n",
      "True Negative:135 False Positive:7\n",
      "False Negative:10 True Positive:148\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       142\n",
      "           1       0.95      0.94      0.95       158\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.94      0.94      0.94       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now with K = ?\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp =confusion_matrix(y_test,pred).ravel()\n",
    "\n",
    "print('WITH K=5')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print('Confusion Matrix Expanded')\n",
    "print('True Negative:{}'.format(tn), 'False Positive:{}'.format(fp))\n",
    "print('False Negative:{}'.format(fn), 'True Positive:{}'.format(tp))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Build a KNN Classifier for yourself using the NBA dataset.\n",
    "\n",
    "It contains 2015 season statistics for ~500 NBA players. This dataset leads to a nice choice of K, as we'll see below. The columns we'll use for features (and the target 'pos') are:\n",
    "\n",
    "\n",
    "| Column | Meaning |\n",
    "| ---    | ---     |\n",
    "| pos | C: Center. F: Front. G: Guard |\n",
    "| ast | Assists per game | \n",
    "| stl | Steals per game | \n",
    "| blk | Blocks per game |\n",
    "| tov | Turnovers per game | \n",
    "| pf  | Personal fouls per game | \n",
    "\n",
    "#### Read the nba data into a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:57:47.376950Z",
     "start_time": "2024-01-09T04:57:47.346620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the NBA data into a DataFrame.\n",
    "import pandas as pd\n",
    "\n",
    "path = './data/NBA_players_2015.csv'\n",
    "nba = pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:57:47.606950Z",
     "start_time": "2024-01-09T04:57:47.582213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map positions to numbers\n",
    "nba['pos_num'] = nba.pos.map({'C':0, 'F':1, 'G':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather some basic info on your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:57:48.143940Z",
     "start_time": "2024-01-09T04:57:48.101369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>pos</th>\n",
       "      <th>age</th>\n",
       "      <th>bref_team_id</th>\n",
       "      <th>g</th>\n",
       "      <th>gs</th>\n",
       "      <th>mp</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg_</th>\n",
       "      <th>...</th>\n",
       "      <th>USG%</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>pos_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season_end</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Quincy Acy</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>NYK</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>19.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.469</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Jordan Adams</td>\n",
       "      <td>G</td>\n",
       "      <td>20</td>\n",
       "      <td>MEM</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.474</td>\n",
       "      <td>...</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>C</td>\n",
       "      <td>21</td>\n",
       "      <td>OKC</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>24.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.550</td>\n",
       "      <td>...</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Jeff Adrien</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>MIN</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.432</td>\n",
       "      <td>...</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Arron Afflalo</td>\n",
       "      <td>G</td>\n",
       "      <td>29</td>\n",
       "      <td>TOT</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>32.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>19.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   player pos  age bref_team_id   g  gs    mp   fg   fga  \\\n",
       "season_end                                                                 \n",
       "2015           Quincy Acy   F   24          NYK  52  21  19.2  2.2   4.6   \n",
       "2015         Jordan Adams   G   20          MEM  18   0   7.3  1.0   2.1   \n",
       "2015         Steven Adams   C   21          OKC  51  50  24.2  3.0   5.5   \n",
       "2015          Jeff Adrien   F   28          MIN  17   0  12.6  1.1   2.6   \n",
       "2015        Arron Afflalo   G   29          TOT  60  54  32.5  5.0  11.8   \n",
       "\n",
       "              fg_  ...  USG%  OWS  DWS   WS  WS/48  OBPM  DBPM  BPM  VORP  \\\n",
       "season_end         ...                                                      \n",
       "2015        0.469  ...  14.7  0.6  0.5  1.0  0.050  -2.6  -0.7 -3.4  -0.3   \n",
       "2015        0.474  ...  17.7  0.0  0.2  0.2  0.076  -2.3   1.8 -0.5   0.0   \n",
       "2015        0.550  ...  14.8  1.0  1.8  2.8  0.109  -2.0   2.0 -0.1   0.6   \n",
       "2015        0.432  ...  14.1  0.2  0.2  0.4  0.093  -2.6   0.8 -1.8   0.0   \n",
       "2015        0.426  ...  19.6  1.4  0.7  2.1  0.051  -0.2  -1.4 -1.6   0.2   \n",
       "\n",
       "            pos_num  \n",
       "season_end           \n",
       "2015              1  \n",
       "2015              2  \n",
       "2015              0  \n",
       "2015              1  \n",
       "2015              2  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:57:48.824098Z",
     "start_time": "2024-01-09T04:57:48.799018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G    200\n",
       "F    199\n",
       "C     79\n",
       "Name: pos, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.pos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:58:08.495680Z",
     "start_time": "2024-01-09T04:58:08.462677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>pos_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season_end</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ast  stl  blk  tov   pf  pos_num\n",
       "season_end                                  \n",
       "2015        1.0  0.4  0.3  0.9  2.2        1\n",
       "2015        0.4  0.4  0.3  0.4  0.8        2\n",
       "2015        1.0  0.4  1.2  1.6  3.0        0\n",
       "2015        0.9  0.2  0.5  0.5  1.8        1\n",
       "2015        1.9  0.6  0.1  1.6  2.1        2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit to the variables we care about to make this easier\n",
    "\n",
    "nba = nba[['ast', 'stl', 'blk', 'tov', 'pf', 'pos_num']]\n",
    "nba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your target variables, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:58:34.679310Z",
     "start_time": "2024-01-09T04:58:34.654445Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create feature matrix (X).\n",
    "feature_cols = ['ast', 'stl', 'blk', 'tov', 'pf']\n",
    "X = nba[feature_cols]\n",
    "\n",
    "# Create response vector (y).\n",
    "y = nba.pos_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale your features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:58:35.603012Z",
     "start_time": "2024-01-09T04:58:35.576683Z"
    }
   },
   "outputs": [],
   "source": [
    "##Import\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "##Instantiate\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fit + transform\n",
    "scaled_features = scaler.fit_transform(nba.drop(\"pos_num\", axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T04:58:59.806596Z",
     "start_time": "2024-01-09T04:58:59.765481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.780000e+02</td>\n",
       "      <td>4.780000e+02</td>\n",
       "      <td>4.780000e+02</td>\n",
       "      <td>4.780000e+02</td>\n",
       "      <td>4.780000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.848003e-17</td>\n",
       "      <td>-5.016907e-17</td>\n",
       "      <td>3.716228e-17</td>\n",
       "      <td>-2.266899e-16</td>\n",
       "      <td>2.229737e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001048e+00</td>\n",
       "      <td>1.001048e+00</td>\n",
       "      <td>1.001048e+00</td>\n",
       "      <td>1.001048e+00</td>\n",
       "      <td>1.001048e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.008278e+00</td>\n",
       "      <td>-1.453864e+00</td>\n",
       "      <td>-8.712793e-01</td>\n",
       "      <td>-1.464769e+00</td>\n",
       "      <td>-2.350562e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.696668e-01</td>\n",
       "      <td>-7.738767e-01</td>\n",
       "      <td>-6.504567e-01</td>\n",
       "      <td>-6.970500e-01</td>\n",
       "      <td>-7.247543e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.310553e-01</td>\n",
       "      <td>-9.388945e-02</td>\n",
       "      <td>-2.088114e-01</td>\n",
       "      <td>-1.852376e-01</td>\n",
       "      <td>-4.733437e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.461677e-01</td>\n",
       "      <td>5.860978e-01</td>\n",
       "      <td>2.328339e-01</td>\n",
       "      <td>4.545280e-01</td>\n",
       "      <td>7.655696e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.748117e+00</td>\n",
       "      <td>3.532709e+00</td>\n",
       "      <td>5.311755e+00</td>\n",
       "      <td>4.037215e+00</td>\n",
       "      <td>3.204282e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ast           stl           blk           tov            pf\n",
       "count  4.780000e+02  4.780000e+02  4.780000e+02  4.780000e+02  4.780000e+02\n",
       "mean   9.848003e-17 -5.016907e-17  3.716228e-17 -2.266899e-16  2.229737e-17\n",
       "std    1.001048e+00  1.001048e+00  1.001048e+00  1.001048e+00  1.001048e+00\n",
       "min   -1.008278e+00 -1.453864e+00 -8.712793e-01 -1.464769e+00 -2.350562e+00\n",
       "25%   -6.696668e-01 -7.738767e-01 -6.504567e-01 -6.970500e-01 -7.247543e-01\n",
       "50%   -3.310553e-01 -9.388945e-02 -2.088114e-01 -1.852376e-01 -4.733437e-02\n",
       "75%    3.461677e-01  5.860978e-01  2.328339e-01  4.545280e-01  7.655696e-01\n",
       "max    4.748117e+00  3.532709e+00  5.311755e+00  4.037215e+00  3.204282e+00"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append the new column to the df\n",
    "nba_feat = pd.DataFrame(scaled_features, columns = nba.columns[:-1])\n",
    "nba_feat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split your data and build a kNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T05:04:31.985003Z",
     "start_time": "2024-01-09T05:04:31.960549Z"
    }
   },
   "outputs": [],
   "source": [
    "# split your data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, nba[\"pos_num\"],\n",
    "                                                   test_size = .3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T05:04:33.543754Z",
     "start_time": "2024-01-09T05:04:33.511866Z"
    }
   },
   "outputs": [],
   "source": [
    "# build your model\n",
    "#Import \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Instantiate\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "#Fit\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#predict\n",
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evalutate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T05:05:05.404922Z",
     "start_time": "2024-01-09T05:05:05.372625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  9  0]\n",
      " [10 29 22]\n",
      " [ 1 14 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.50      0.47        18\n",
      "           1       0.56      0.48      0.51        61\n",
      "           2       0.69      0.77      0.73        65\n",
      "\n",
      "    accuracy                           0.61       144\n",
      "   macro avg       0.57      0.58      0.57       144\n",
      "weighted avg       0.61      0.61      0.61       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: Search the hyperparameter space for the best kNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T05:06:28.682925Z",
     "start_time": "2024-01-09T05:06:27.962263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "k = np.arange(50) + 1\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {'n_neighbors': k}\n",
    "\n",
    "#Note! CV should be no more than 25% of the data!\n",
    "gs = GridSearchCV(    \n",
    "    estimator= knn,\n",
    "    param_grid= params,\n",
    "    cv=3)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "#Check the documentation! How do you get only the best k? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T05:07:39.727435Z",
     "start_time": "2024-01-09T05:07:39.702856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 16}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T05:09:29.413576Z",
     "start_time": "2024-01-09T05:09:29.370988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  8  1]\n",
      " [ 5 42 14]\n",
      " [ 1 17 47]]\n",
      "\n",
      "\n",
      "WITH K=16\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        18\n",
      "           1       0.63      0.69      0.66        61\n",
      "           2       0.76      0.72      0.74        65\n",
      "\n",
      "    accuracy                           0.68       144\n",
      "   macro avg       0.66      0.64      0.65       144\n",
      "weighted avg       0.68      0.68      0.68       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now with K = ?\n",
    "knn = KNeighborsClassifier(n_neighbors = 16)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print('WITH K=16')\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
