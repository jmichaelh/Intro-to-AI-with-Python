{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Objectives\n",
    "- Define linear regression.\n",
    "- Build a linear regression model using a data set\n",
    "- Learn a method for finding the best fitting model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview-of-supervised-learning\"></a>\n",
    "## Overview of Supervised Learning\n",
    "---\n",
    "\n",
    "![Supervised learning diagram](./assets/supervised_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Model?\n",
    "\n",
    "A Model in our context is an artifact created by the machine learning process one might even consider a program in its own right. The model will accept data and return the appropriate output. \n",
    "\n",
    "The overall process looks like this:\n",
    "\n",
    "1. Form a question we want to test/explore in the form of \"Can I predict y with X features?\"\n",
    "\n",
    "2. Load, clean and transform relevant data\n",
    "\n",
    "3. Identify relevant features/variables for both the question and the model\n",
    "\n",
    "4. Build a process with an appropriate machine learning algorithm that suits your data, use case, and available computational resources\n",
    "\n",
    "5. Test, evaluate and refine your model. Often, you'll need to iterate on the model to get the best output\n",
    "\n",
    "6. Deploy the model - Batch processing or live endpoint (we won't cover this in the class)\n",
    "\n",
    "7. Monitor and refine the model over time\n",
    "\n",
    "\n",
    "The end result is a clear and defined process to accept raw information and create predictive or prosciptive insights to your organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduce-the-bikeshare-dataset\"></a>\n",
    "## Introduce the Bikeshare Data Set\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with a data set from Capital Bikeshare that was used in a Kaggle competition ([data dictionary](https://www.kaggle.com/c/bike-sharing-demand/data)).\n",
    "\n",
    "The objective of the competition is to **predict total ridership of Capital Bikeshare in any given hour.**\n",
    "\n",
    "Demand forecasting is a common data science application. If we can predict the quantity of demand, total ridership in a given hour, we can create analytical tools to improve the bikeshare system. \n",
    "Some applications would be:\n",
    "* Find where to site new bikeshare stations and know how large of a station to build.\n",
    "* Calculate the expected wear and tear on bikes and what the replacement costs will be.\n",
    "* Use a slightly different research design to forecast full and empty stations and send a service vehicle to \"rebalance\" the bikes from one station to another, as sometimes bikeshare stations have no bikes or are completely full and prevent use of the station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T04:46:14.316001Z",
     "start_time": "2024-01-08T04:46:14.292541Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:25:50.236314Z",
     "start_time": "2024-03-11T20:25:50.194912Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"read-in-the--capital-bikeshare-data\"></a>\n",
    "### Read In the Capital Bikeshare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:26:39.237319Z",
     "start_time": "2024-03-11T20:26:39.187039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the data and set the datetime as the index.\n",
    "url = './data/bikeshare.csv'\n",
    "bikes = pd.read_csv(url, index_col='datetime', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:28:26.890088Z",
     "start_time": "2024-03-11T20:28:26.841916Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preview the first five rows of the DataFrame.\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does each observation represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T05:50:07.307270Z",
     "start_time": "2024-01-08T05:50:07.284847Z"
    }
   },
   "outputs": [],
   "source": [
    "# A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the response variable (as defined by Kaggle)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T05:50:07.817975Z",
     "start_time": "2024-01-08T05:50:07.799255Z"
    }
   },
   "outputs": [],
   "source": [
    "# A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many features are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:33:37.206791Z",
     "start_time": "2024-03-11T20:33:37.177603Z"
    }
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See any issues with column names?\n",
    "\n",
    "| Variable| Description |\n",
    "|---------|----------------|\n",
    "|datetime| hourly date + timestamp  |\n",
    "|season|  1=winter, 2=spring, 3=summer, 4=fall |\n",
    "|holiday| whether the day is considered a holiday|\n",
    "|workingday| whether the day is neither a weekend nor holiday|\n",
    "|weather| 1=Clear, 2=Partly cloudy, 3=Light rain or snow, 4=Heavy rain, snow, storms|\n",
    "|temp| temperature in Celsius|\n",
    "|atemp| \"feels like\" temperature in Celsius|\n",
    "|humidity| relative humidity|\n",
    "|windspeed| wind speed|\n",
    "|casual| number of non-registered user rentals initiated|\n",
    "|registered| number of registered user rentals initiated|\n",
    "|**count**| number of total rentals|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:36:41.709331Z",
     "start_time": "2024-03-11T20:36:41.684798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the .rename() method to rename count to total\n",
    "bikes.rename(columns={'count':'total_rentals'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:36:43.542237Z",
     "start_time": "2024-03-11T20:36:43.509493Z"
    }
   },
   "outputs": [],
   "source": [
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualizing-the-data\"></a>\n",
    "### Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building a model, it's important to have or gain as much background knowledge or business context as you can to the problem you're trying to solve. Visualizing your data can help with this and may also surprise your intuition about the relationships to the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View the distribution of total rentals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:43:38.422720Z",
     "start_time": "2024-03-11T20:43:38.100012Z"
    }
   },
   "outputs": [],
   "source": [
    "bikes.total_rentals.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:42:34.485318Z",
     "start_time": "2024-03-11T20:42:34.458275Z"
    }
   },
   "outputs": [],
   "source": [
    "help(bikes.total_rentals.plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View variable correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:50:13.511951Z",
     "start_time": "2024-03-11T20:50:13.471050Z"
    }
   },
   "outputs": [],
   "source": [
    "bikes.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:46:19.176235Z",
     "start_time": "2024-03-11T20:46:18.797751Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.clustermap(bikes.corr());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable relationships**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:50:00.424173Z",
     "start_time": "2024-03-11T20:50:00.162822Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas scatterplot\n",
    "bikes.plot(kind='scatter', x='registered', y='total_rentals', alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classroom Discussion\n",
    "What is wrong with using `registered` as a variable in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:09:40.129399Z",
     "start_time": "2024-03-11T21:09:39.870814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas scatterplot\n",
    "bikes.plot(kind='scatter', x='temp', y='total_rentals', alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:10:38.737047Z",
     "start_time": "2024-03-11T21:10:37.945252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seaborn scatterplot with regression line\n",
    "sns.lmplot(x='temp', y='total_rentals', data=bikes, aspect=1.5, scatter_kws={'alpha':0.2});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:14:27.520425Z",
     "start_time": "2024-03-11T21:14:27.326399Z"
    }
   },
   "outputs": [],
   "source": [
    "bikes.total_rentals.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"linear-regression-basics\"></a>\n",
    "## Linear Regression Basics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Key assumptions:\n",
    "\n",
    "1. Linear relationship between target and features\n",
    "2. Data is normally distributed or contains Multivariate normality (but doesn't have to be)\n",
    "3. No or little multicollinearity\n",
    "4. No auto-correlation\n",
    "5. Homoscedasticity\n",
    "6. Independent features\n",
    "\n",
    "Note: If data is not normally distributed, we could be introducing bias\n",
    "\n",
    "**1. Linear Relationship** \n",
    "\n",
    "First, linear regression needs the relationship between the independent and dependent variables to be linear.  It is also important to check for outliers since linear regression is sensitive to outlier effects.  The linearity assumption can best be tested with scatter plots\n",
    "\n",
    "**2. Normal Distribution**\n",
    "\n",
    "Since the linear regression analysis requires all variables to be multivariate normal it can be checked with a histogram or Q-Q plot. When the data is not normally distributed it's possible a non-linear transformation (e.g., log-transformation) might fix this issue.\n",
    "\n",
    "**3. Low to No Multicollinearity**\n",
    "\n",
    "Multicollinearity occurs when the independent variables are too highly correlated with each other. A quick way to test this is our tried and true correlation matrix. \n",
    "\n",
    "**4. Low to No Auto-correlation**\n",
    "\n",
    "Linear regression analysis requires that there is little or no autocorrelation in the data.  Autocorrelation occurs when the residuals are not independent from each other.  In other words when the value of y(x+1) is not independent from the value of y(x). Examples are signal processing or time series data\n",
    "\n",
    "\n",
    "**5. Homoscedasticity**\n",
    "\n",
    "Homoscedastic data means the residuals are equal across the regression line. We can test this with scatterplots or seaborn's lmplot()\n",
    "\n",
    "**6. Independent features**\n",
    "\n",
    "Independent features are in no way derived from other features. Otherwise, we have a problem when interpreting the model since we expect to interpret our outputs as X increase in feature A drives an increase of Y units of the response variable. However, if features are correlated, you lose the ability to interpret the linear regression model because you violate a fundamental assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id=\"form-of-linear-regression\"></a>\n",
    "### Form of Linear Regression\n",
    "\n",
    "Recall that each model always contains some amount of random irreducible error $\\epsilon$. So, given a prediction $\\hat{y}$, the actual $y = \\hat{y} + \\epsilon$. Below, we will assume $y$ is exactly linear.\n",
    "\n",
    "- We are often taught the formula for a line is: $y = mx + b$.\n",
    "- Note this can alternatively be written: $y = \\alpha + \\beta X$.\n",
    "\n",
    "---\n",
    "\n",
    "Here, we will generalize this to $n$ independent variables as follows:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n + \\epsilon$\n",
    "\n",
    "- $y$ is the response.\n",
    "- $\\beta_0$ is the intercept.\n",
    "- $\\beta_1$ is the coefficient for $x_1$ (the first feature).\n",
    "- $\\beta_n$ is the coefficient for $x_n$ (the nth feature).\n",
    "- $\\epsilon$ is the _error_ term\n",
    "\n",
    "A practical example of this applied to our data might be:\n",
    "\n",
    "$total\\_rides = 20 + -2 \\cdot temp + -3 \\cdot windspeed\\ +\\ ...\\ $\n",
    "\n",
    "This equation is still called **linear** because the highest degree of the independent variables (e.g. $x_i$) is 1. Note that because the $\\beta$ values are constants, they will not be independent variables in the final model, as seen above.\n",
    "\n",
    "---\n",
    "\n",
    "The $\\beta$ values are called the **model coefficients**:\n",
    "\n",
    "- These values are estimated (or \"learned\") during the model fitting process using the **least squares criterion**.\n",
    "- Specifically, we are trying to find the line (mathematically) that minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n",
    "- Once we've learned these coefficients, we can use the model to predict the response.\n",
    "\n",
    "![Estimating coefficients](./assets/estimating_coefficients.png)\n",
    "\n",
    "In the diagram above:\n",
    "\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the vertical distances between the observed values and the least squares line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"building-a-linear-regression-model-in-sklearn\"></a>\n",
    "### Building a Linear Regression Model in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a feature matrix called X that holds a `DataFrame` with only the temp variable and a `Series` called y that has the \"total_rentals\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:45:56.171826Z",
     "start_time": "2024-03-11T21:45:56.149346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create X and y.\n",
    "feature_cols = ['temp']\n",
    "X = bikes[feature_cols]\n",
    "y = bikes.total_rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:44:31.999461Z",
     "start_time": "2024-03-11T21:44:31.976921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check X's type.\n",
    "print((type(X)))\n",
    "print((type(X.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:44:32.411575Z",
     "start_time": "2024-03-11T21:44:32.384789Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check y's type.\n",
    "print((type(y)))\n",
    "print((type(y.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:44:32.947055Z",
     "start_time": "2024-03-11T21:44:32.922143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check X's shape (n = number of observations, p = number of features).\n",
    "print((X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:44:33.774572Z",
     "start_time": "2024-03-11T21:44:33.753179Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check y's shape (single dimension with length n).\n",
    "# The comma indicates the datatype is a tuple.\n",
    "print((y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scikit-learns--step-modeling-pattern\"></a>\n",
    "### scikit-learn's Four-Step Modeling Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import the class you plan to use. <br> \n",
    "**Step 2:** \"Instantiate\" the \"estimator.\" <br>\n",
    "**Step 3:** Fit the model with data (aka \"model training\"). <br>\n",
    "**Step 4:** Predict the response for a new observation. <br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**Step 1:** Import the class you plan to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:47:29.932319Z",
     "start_time": "2024-03-11T21:47:29.787540Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** \"Instantiate\" the \"estimator.\"\n",
    "\n",
    "- \"Estimator\" is scikit-learn's term for \"model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:47:46.508007Z",
     "start_time": "2024-03-11T21:47:46.481441Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make an instance of a LinearRegression object.\n",
    "lr = LinearRegression()\n",
    "type(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the possible parameters, either use the `help` built-in function or evaluate the newly instantiated model, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:48:26.791070Z",
     "start_time": "2024-03-11T21:48:26.767388Z"
    }
   },
   "outputs": [],
   "source": [
    "# help(lr)\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Fit the model with data (aka \"model training\").\n",
    "\n",
    "- Model is \"learning\" the relationship between X and y in our \"training data.\"\n",
    "- Process through which learning occurs varies by model.\n",
    "- Occurs in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:49:03.184286Z",
     "start_time": "2024-03-11T21:49:02.958828Z"
    }
   },
   "outputs": [],
   "source": [
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:49:58.136657Z",
     "start_time": "2024-03-11T21:49:58.109309Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the coefficients.\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the intercept ($\\beta_0$):\n",
    "\n",
    "- It is the value of $y$ when all independent variables are 0.\n",
    "- Here, it is the estimated number of rentals when the temperature is 0 degrees Celsius.\n",
    "- **Note:** It does not always make sense to interpret the intercept. (Why?)\n",
    "\n",
    "Interpreting the \"temp\" coefficient ($\\beta_1$):\n",
    "\n",
    "- **Interpretation:** An increase of 1 degree Celcius is _associated with_ increasing the number of total rentals by $\\beta_1$.\n",
    "- Here, a temperature increase of 1 degree Celsius is _associated with_ a rental increase of 9.17 bikes.\n",
    "- This is not a statement of causation.\n",
    "- $\\beta_1$ would be **negative** if an increase in temperature was associated with a **decrease** in total rentals.\n",
    "- $\\beta_1$ would be **zero** if temperature is not associated with total rentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:53:10.547910Z",
     "start_time": "2024-03-11T21:53:10.520035Z"
    }
   },
   "outputs": [],
   "source": [
    "dict(zip(X.columns,lr.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Predict the response for a new observation.\n",
    "\n",
    "- Uses the information it learned during the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:56:27.492028Z",
     "start_time": "2024-03-11T21:56:27.461656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Per future warning, one-dimensional arrays must be reshaped using the following.\n",
    "lr.predict(np.array([0]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask the model to make two predictions, one when the `temp` is 0 and another when the `temp` is 10. To do this, our feature matrix is always a 2-D array where each row is a list of features. Since we only have a single feature, the temperature, each row will contain only a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:57:40.860868Z",
     "start_time": "2024-03-11T21:57:40.834081Z"
    }
   },
   "outputs": [],
   "source": [
    "X_new = [[0], [10]]\n",
    "lr.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Returns a NumPy array, and we keep track of what the numbers \"mean.\"\n",
    "- Can predict for multiple observations at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we just predicted using our model is, \"If the temperature is 0 degrees, the total number of bike rentals will be ~6.046, and if the temperature is 10 degrees the total number of bike rentals will ~97.751.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Format for sklearn model classes & methods\n",
    "\n",
    "#### Generate an instance of an estimator class\n",
    "estimator = base_models.AnySKLearnObject()\n",
    "#### Fit your data\n",
    "estimator.fit(X, y)\n",
    "#### Score it with the default scoring method (recommended to use the metrics module in the future)\n",
    "estimator.score(X, y)\n",
    "#### Predict a new set of data\n",
    "estimator.predict(new_X)\n",
    "#### Transform a new X if changes were made to the original X while fitting\n",
    "estimator.transform(new_X)\n",
    "\n",
    "- LinearRegression() doesnâ€™t have a transform function\n",
    "\n",
    "- With this information, we can build a simple process for linear regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build-a-linear-regression-model\"></a>\n",
    "### Exercises\n",
    "\n",
    "#### 1. Las Vegas Simple Model\n",
    "We will use a [dataset](https://archive.ics.uci.edu/ml/datasets/Las+Vegas+Strip) of Tripadvisor reviews of Las Vegas hotels from 2015 to build a regression model predicting the customers score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:59:38.034673Z",
     "start_time": "2024-03-11T21:59:38.003300Z"
    }
   },
   "outputs": [],
   "source": [
    "lv_reviews = pd.read_csv('./data/LasVegasTripAdvisorReviews-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T21:59:40.883015Z",
     "start_time": "2024-03-11T21:59:40.848437Z"
    }
   },
   "outputs": [],
   "source": [
    "lv_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a correlation clustermap of the variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:34:44.570513Z",
     "start_time": "2024-03-11T22:34:44.176086Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View the distribution of the Score variable using a histogram.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:37:27.398273Z",
     "start_time": "2024-03-11T22:37:27.217402Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create X and y using Hotel stars as the X variable and Score as the y variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:38:53.585373Z",
     "start_time": "2024-03-11T22:38:53.558934Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate and fit a `LinearRegression` model on X and y from the `linear_model` section of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:41:23.843335Z",
     "start_time": "2024-03-11T22:41:23.813704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import, instantiate, fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the coefficients and intercept.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:42:34.340306Z",
     "start_time": "2024-03-11T22:42:34.313709Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret the coefficients and intercept.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T05:50:19.322407Z",
     "start_time": "2024-01-08T05:50:19.300332Z"
    }
   },
   "outputs": [],
   "source": [
    "# B0: \n",
    "# B1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"using-the-model-for-prediction\"></a>\n",
    "## Using the Model for Prediction\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many bike rentals would we predict if the temperature was 25 degrees Celsius?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the intercept and coefficients of the linear model.\n",
    "\n",
    "You can search for \"sklearn linear regression\" and explore the attributes section of the documentation to learn how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:47:16.517114Z",
     "start_time": "2024-03-11T22:47:16.489909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Manually calculate the prediction.\n",
    "print(lr.intercept_+lr.coef_*5)\n",
    "print(3.3667728237791925+0.18683652*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:50:50.026862Z",
     "start_time": "2024-03-11T22:50:49.998811Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the predict method.\n",
    "lr.predict([[5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does the scale of the features matter?** \n",
    "\n",
    "No, the scale of the features is irrelevant for linear regression models. When changing the scale, we simply change our interpretation of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"work-with-multiple-features\"></a>\n",
    "## Work With Multiple Features\n",
    "---\n",
    "\n",
    "We've demonstrated simple linear regression with one feature to gain an intuition, but the benefit of modeling is the ability to reason about hundreds of features at once (ignoring the curse of dimensionality for the moment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualizing-the-data-part-\"></a>\n",
    "### Visualizing the Data (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:51:25.821324Z",
     "start_time": "2024-03-11T22:51:25.795866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create feature column variables\n",
    "feature_cols = ['temp', 'season', 'weather', 'humidity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a subset of scatterplot matrix using Seaborn.\n",
    "We can use pairplot with the y_vars argument to only show relationships with the `total_rentals` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:51:36.418507Z",
     "start_time": "2024-03-11T22:51:33.837838Z"
    }
   },
   "outputs": [],
   "source": [
    "# multiple scatterplots in Seaborn\n",
    "sns.pairplot(bikes, x_vars=feature_cols, y_vars='total_rentals', kind='reg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:53:01.474373Z",
     "start_time": "2024-03-11T22:52:57.914909Z"
    }
   },
   "outputs": [],
   "source": [
    "grr = pd.plotting.scatter_matrix(bikes[['total_rentals'] + feature_cols], figsize=(15, 15), alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are you seeing anything you didn't expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the season variable using a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:54:47.698013Z",
     "start_time": "2024-03-11T22:54:47.508072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Box plot of rentals, grouped by season\n",
    "bikes.boxplot(column='total_rentals', by='season');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at rentals over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:54:58.117550Z",
     "start_time": "2024-03-11T22:54:57.846677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Line plot of rentals\n",
    "bikes.total_rentals.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does this tell us?\n",
    "\n",
    "There are more rentals in the winter than the spring, but only because the system is experiencing overall growth and the winter months happen to come after the spring months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"adding-more-features-to-the-model\"></a>\n",
    "### Adding More Features to the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, one variable explained the variance of another; however, more often than not, we will need multiple variables. How many real-world problems can be explained with just one variable? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create another `LinearRegression` instance that is fit using temp, season, weather, and humidity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:57:14.769580Z",
     "start_time": "2024-03-11T22:57:14.745346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of features.\n",
    "feature_cols = ['temp', 'season', 'weather', 'humidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:57:38.199300Z",
     "start_time": "2024-03-11T22:57:38.167783Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create X and y.\n",
    "X = bikes[feature_cols]\n",
    "y = bikes.total_rentals\n",
    "\n",
    "# Instantiate and fit.\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "# Print the coefficients.\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the linear regression coefficient along with the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T22:57:50.235106Z",
     "start_time": "2024-03-11T22:57:50.206757Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pair the feature names with the coefficients.\n",
    "list(zip(feature_cols, linreg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-multicollinearity\"></a>\n",
    "## What Is Multicollinearity?\n",
    "---\n",
    "\n",
    "Multicollinearity happens when two or more features are highly correlated with each other. The problem is that due to the high correlation, it's hard to disambiguate which feature has what kind of effect on the outcome. In other words, the features mask each other. \n",
    "\n",
    "There is a second related issue called variance inflation where including correlated features increases the variability of our model and p-values by widening the standard errors. This can be measured with the variance inflation factor, which we will not cover here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a linear model that predicts `total_rentals` using `temp` and `atemp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:02:35.042257Z",
     "start_time": "2024-03-11T23:02:35.016904Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of features.\n",
    "feature_cols = ['atemp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:02:35.885463Z",
     "start_time": "2024-03-11T23:02:35.859905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create X and y.\n",
    "X = bikes[feature_cols]\n",
    "y = bikes.total_rentals\n",
    "\n",
    "# Instantiate and fit.\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "# Print the coefficients.\n",
    "print(linreg.intercept_)\n",
    "print(list(zip(feature_cols,linreg.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Go back and remove either `temp` or `atemp` from the feature list. How do the coefficients change? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T05:50:33.298237Z",
     "start_time": "2024-01-08T05:50:33.275725Z"
    }
   },
   "outputs": [],
   "source": [
    "# A:\n",
    "#feature_cols = ['temp']\n",
    "#feature_cols = ['atemp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "#### 2. Las Vegas Multiple Variable Model \n",
    "Using the Las Vegas Trip Advisor data, build a model using 2 variables: `Hotel stars` and `Nr. reviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:02:52.211736Z",
     "start_time": "2024-03-11T23:02:52.184716Z"
    }
   },
   "outputs": [],
   "source": [
    "lv_reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:31:23.145626Z",
     "start_time": "2024-03-11T23:31:23.121718Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:30:43.280161Z",
     "start_time": "2024-03-11T23:30:43.252231Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:33:55.685844Z",
     "start_time": "2024-03-11T23:33:55.649999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of features.\n",
    "\n",
    "\n",
    "# Create X and y.\n",
    "\n",
    "\n",
    "# Instantiate and fit.\n",
    "\n",
    "\n",
    "# Print the coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:37:18.479444Z",
     "start_time": "2024-03-11T23:37:18.451845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pair the feature names with the coefficients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give your interpretations of the coefficients.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would be your next steps?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform, Score and compare RMSE.\n",
    "<a id=\"how-to-select-a-model\"></a>\n",
    "## How to Select a Model\n",
    "---\n",
    "\n",
    "How do we know we have the best model for our application? Here's one way to go about selecting which model is best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"feature-selection\"></a>\n",
    "### Feature Selection\n",
    "\n",
    "How do we choose which features to include in the model? We're going to use **train/test split** (and eventually **cross-validation**).\n",
    "\n",
    "Why not use p-values or R-squared for feature selection?\n",
    "\n",
    "- Linear models rely upon a lot of assumptions (such as the features being independent), and if those assumptions are violated, p-values and R-squared are less reliable. Train/test split relies on fewer assumptions.\n",
    "- If all of the assumptions of a linear model are met, p-values suggest a coefficient that differs from zero at a level of statistical significance. This does not mean that\n",
    "    1. the feature _causes_ the response\n",
    "    2. the feature strongly _predicts_ the response. \n",
    "- Adding features to your model that are unrelated to the response will always increase the R-squared value, and adjusted R-squared does not sufficiently account for this (although, AIC and BIC do).\n",
    "- p-values and R-squared are **proxies** for our goal of generalization, whereas train/test split and cross-validation attempt to directly estimate how well the model will generalize to out-of-sample data.\n",
    "\n",
    "More generally:\n",
    "\n",
    "- There are different methodologies that can be used for solving any given data science problem, and this course follows a machine learning methodology.\n",
    "- This course focuses on general purpose approaches that can be applied to any model, rather than model-specific approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluation-metrics-for-regression-problems\"></a>\n",
    "### Evaluation Metrics for Regression Problems\n",
    "\n",
    "Evaluation metrics for classification problems, such as accuracy, are not useful for regression problems. We need evaluation metrics designed for comparing continuous values.\n",
    "\n",
    "Here are three common evaluation metrics for regression problems:\n",
    "\n",
    "**Mean absolute error (MAE)** is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean squared error (MSE)** is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root mean squared error (RMSE)** is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:45:27.557721Z",
     "start_time": "2024-03-11T23:45:27.534958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example true and predicted response values\n",
    "true = [10, 7, 5, 5]\n",
    "pred = [8, 6, 5, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate MAE, MSE, and RMSE using imports from sklearn metrics and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:45:55.740041Z",
     "start_time": "2024-03-11T23:45:55.714908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate these metrics by hand!\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print('MAE:', metrics.mean_absolute_error(true, pred))\n",
    "print('MSE:', metrics.mean_squared_error(true, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(true, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare these metrics:\n",
    "\n",
    "- MAE is the easiest to understand, because it's the average error.\n",
    "- MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world. Also, MSE is continuous and differentiable, making it easier to use than MAE for optimization.\n",
    "- RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "All of these are **loss functions**, because we want to minimize them.\n",
    "\n",
    "Here's an additional example, to demonstrate how MSE/RMSE punishes larger errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:47:25.989275Z",
     "start_time": "2024-03-11T23:47:25.962514Z"
    }
   },
   "outputs": [],
   "source": [
    "# Same true values as above\n",
    "true = [10, 7, 5, 5]\n",
    "\n",
    "# New set of predicted values\n",
    "pred = [10, 7, 5, 13]\n",
    "\n",
    "# MAE is the same as before.\n",
    "print('MAE:', metrics.mean_absolute_error(true, pred))\n",
    "\n",
    "# MSE and RMSE are larger than before.\n",
    "print('MSE:', metrics.mean_squared_error(true, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(true, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-models-with-traintest-split-and-rmse\"></a>\n",
    "### Comparing Models With Train/Test Split and RMSE\n",
    "\n",
    "![](./assets/Train-Test-Split-CV.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:58:47.296496Z",
     "start_time": "2024-03-11T23:58:47.225416Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a function that accepts a list of features and returns testing RMSE.\n",
    "def train_test_rmse(df, feature_cols, response):\n",
    "    X = df[feature_cols]\n",
    "    y = df[response]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "    \n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = linreg.predict(X_test)\n",
    "    return np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T23:58:47.796387Z",
     "start_time": "2024-03-11T23:58:47.756136Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare different sets of features.\n",
    "print(train_test_rmse(bikes, ['temp', 'season', 'weather', 'humidity'], 'total_rentals'))\n",
    "print(train_test_rmse(bikes, ['temp', 'season', 'weather'],'total_rentals'))\n",
    "print(train_test_rmse(bikes, ['temp', 'season', 'humidity'],'total_rentals'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T00:00:37.107837Z",
     "start_time": "2024-03-12T00:00:37.071729Z"
    }
   },
   "outputs": [],
   "source": [
    "# Append scores to dataset\n",
    "X = bikes[['temp', 'season', 'humidity']]\n",
    "y = bikes['total_rentals']\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "    \n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "bikes['y_pred']= linreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T00:00:44.785986Z",
     "start_time": "2024-03-12T00:00:44.753629Z"
    }
   },
   "outputs": [],
   "source": [
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T00:01:10.595814Z",
     "start_time": "2024-03-12T00:01:10.562710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using these as features is not allowed!\n",
    "print(train_test_rmse(bikes, ['casual', 'registered'],'total_rentals'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:10:12.231170Z",
     "start_time": "2024-03-12T16:10:12.186924Z"
    }
   },
   "outputs": [],
   "source": [
    "lv_reviews.groupby('Hotel name').mean('Score')#.reset_index()[['Hotel name', 'Score']]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-testing-rmse-with-null-rmse\"></a>\n",
    "### Comparing Testing RMSE With Null RMSE\n",
    "\n",
    "Null RMSE is the RMSE that could be achieved by always predicting the mean response value. It is a benchmark against which you may want to measure your regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:37:25.459920Z",
     "start_time": "2024-03-12T16:37:25.386610Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Create X and y.\n",
    "X = bikes['temp']\n",
    "y = bikes.total_rentals\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "\n",
    "# Create a dummy regressor\n",
    "dummy_mean = DummyRegressor(strategy='mean')\n",
    "\n",
    "# \"Train\" dummy regressor\n",
    "dummy_mean.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:37:59.753489Z",
     "start_time": "2024-03-12T16:37:59.723007Z"
    }
   },
   "outputs": [],
   "source": [
    "#Save Predictions\n",
    "y_pred_dummy = dummy_mean.predict(X_test)\n",
    "\n",
    "#Testing MSE\n",
    "print(metrics.mean_squared_error(y_test, y_pred_dummy))\n",
    "\n",
    "#Testing RMSE\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred_dummy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "#### 3. Las Vegas Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a baseline/null model result to compare your models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:13:49.874976Z",
     "start_time": "2024-03-12T17:13:49.847510Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create X and y.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split X and y into training and testing sets.\n",
    "\n",
    "# Create a dummy regressor\n",
    "\n",
    "# \"Train\" dummy regressor\n",
    "\n",
    "#Save Predictions\n",
    "\n",
    "\n",
    "#Testing RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:13:15.338081Z",
     "start_time": "2024-03-12T17:13:15.310396Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the single variable and multiple variable models using the `train_test_rmse` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:16:20.446678Z",
     "start_time": "2024-03-12T17:16:20.415411Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:16:42.394018Z",
     "start_time": "2024-03-12T17:16:42.363917Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which model is better?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is the RMSE significantly lower than the RMSE in the bikes model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"feature-engineering-to-improve-performance\"></a>\n",
    "## Feature Engineering to Improve Performance\n",
    "---\n",
    "\n",
    "Machine learning models are very powerful, but they cannot automatically handle every aspect of our data. We have to explicitly modify our features to have relationships that our models can understand. In this case, we will need to pull out features to have a linear relationship with our response variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"handling-categorical-features\"></a>\n",
    "### Handling Categorical Features\n",
    "\n",
    "scikit-learn expects all features to be numeric. So how do we include a categorical feature in our model?\n",
    "\n",
    "- **Ordered categories:** Transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** Use dummy encoding (0/1). Here, each possible category would become a separate feature.\n",
    "\n",
    "What are the categorical features in our data set?\n",
    "\n",
    "- **Ordered categories:** `weather` (already encoded with sensible numeric values)\n",
    "- **Unordered categories:** `season` (needs dummy encoding), `holiday` (already dummy encoded), `workingday` (already dummy encoded)\n",
    "\n",
    "For season, we can't simply leave the encoding as 1 = spring, 2 = summer, 3 = fall, and 4 = winter, because that would imply an ordered relationship. Instead, we create multiple dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:30:14.346048Z",
     "start_time": "2024-03-12T17:30:14.272817Z"
    }
   },
   "outputs": [],
   "source": [
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummy variables using `get_dummies` from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:31:11.913521Z",
     "start_time": "2024-03-12T17:31:11.886474Z"
    }
   },
   "outputs": [],
   "source": [
    "season_dummies = pd.get_dummies(bikes.season, prefix='season')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:32:27.159905Z",
     "start_time": "2024-03-12T17:32:27.135744Z"
    }
   },
   "outputs": [],
   "source": [
    "bikes.season.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the `DataFrame` of `dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:31:15.853347Z",
     "start_time": "2024-03-12T17:31:15.822616Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print five random rows.\n",
    "season_dummies.sample(n=5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we actually only need three dummy variables (not four), and thus we'll drop the first dummy variable.\n",
    "\n",
    "Why? Because three dummies captures all of the \"information\" about the season feature, and implicitly defines spring (season 1) as the baseline level.\n",
    "\n",
    "This circles back to the concept multicollinearity, except instead of one feature being highly correlated to another, the information gained from three features is directly correlated to the fourth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:35:58.621883Z",
     "start_time": "2024-03-12T17:35:58.595011Z"
    }
   },
   "outputs": [],
   "source": [
    "season_dummies.drop(season_dummies.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinspect the `DataFrame` of `dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:38:38.445991Z",
     "start_time": "2024-03-12T17:38:38.414854Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print five random rows.\n",
    "season_dummies.sample(n=5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, if you have a categorical feature with k possible values, you create k-1 dummy variables.\n",
    "\n",
    "If that's confusing, think about why we only need one dummy variable for `holiday`, not two dummy variables (`holiday_yes` and `holiday_no`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now need to concatenate the two `DataFrames` together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:47:51.721540Z",
     "start_time": "2024-03-12T17:47:51.641237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate the original DataFrame and the dummy DataFrame (axis=0 means rows, axis=1 means columns).\n",
    "bikes_dummies = pd.concat([bikes, season_dummies], axis=1)\n",
    "\n",
    "# Print 5 random rows.\n",
    "bikes_dummies.sample(n=5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerun the linear regression with dummy variables included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:48:48.184314Z",
     "start_time": "2024-03-12T17:48:48.152307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Include dummy variables for season in the model.\n",
    "feature_cols = ['temp', 'season_2', 'season_3', 'season_4', 'humidity']\n",
    "X = bikes_dummies[feature_cols]\n",
    "y = bikes_dummies.total_rentals\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "list(zip(feature_cols, linreg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret the season coefficients? They are measured against the baseline (spring):\n",
    "\n",
    "- Holding all other features fixed, summer is associated with a rental decrease of 3.39 bikes compared to the spring.\n",
    "- Holding all other features fixed, fall is associated with a rental decrease of 41.7 bikes compared to the spring.\n",
    "- Holding all other features fixed, winter is associated with a rental increase of 64.4 bikes compared to the spring.\n",
    "\n",
    "Would it matter if we changed which season was defined as the baseline?\n",
    "\n",
    "- No, it would simply change our interpretation of the coefficients.\n",
    "\n",
    "In most situations, it is best to have the dummy that is your baseline be the category that has the largest representation.\n",
    "\n",
    "**Important:** Dummy encoding is relevant for all machine learning models, not just linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:50:37.351351Z",
     "start_time": "2024-03-12T17:50:37.316466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compare original season variable with dummy variables.\n",
    "print(train_test_rmse(bikes_dummies, ['temp', 'season', 'humidity'],'total_rentals'))\n",
    "print(train_test_rmse(bikes_dummies, ['temp', 'season_2', 'season_3', 'season_4', 'humidity'],'total_rentals'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T05:35:40.307745Z",
     "start_time": "2024-01-08T05:35:40.280103Z"
    }
   },
   "source": [
    "## Bias & Variance\n",
    "**Conceptual Definitions**\n",
    "- **Bias**: How close are predictions to the actual values?\n",
    "  - **Accuracy.** Roughly, whether or not our model aims on target.\n",
    "  - If the model cannot represent the data's structure, our predictions could be consistent, but will not be accurate.\n",
    "- **Variance**: How variable are our predictions?\n",
    "  - **Precision.** Roughly, whether or not our model is reliable.\n",
    "  - We will make slightly different predictions given slightly different training sets.\n",
    "  \n",
    "![](./assets/biasVsVarianceImage.png)\n",
    "\n",
    "- Visually, we are building a model where the bulls-eye is the goal.\n",
    "- Each individual hit is one prediction based on our model.\n",
    "- Critically, the success of our model **(low variance, low bias)** depends on the training data present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T05:37:01.457689Z",
     "start_time": "2024-01-08T05:37:01.297232Z"
    }
   },
   "source": [
    "![Bias-variance tradeoff](./assets/bias_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bonus-material-regularization\"></a>\n",
    "## Regularization\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regularization is a method for \"constraining\" or \"regularizing\" the size of the coefficients, thus \"shrinking\" them toward zero.\n",
    "- It reduces model variance and thus minimizes overfitting.\n",
    "- If the model is too complex, it tends to reduce variance more than it increases bias, resulting in a model that is more likely to generalize.\n",
    "\n",
    "Our goal is to locate the optimum model complexity, and thus regularization is useful when we believe our model is too complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"how-does-regularization-work\"></a>\n",
    "### How Does Regularization Work?\n",
    "\n",
    "For a normal linear regression model, we estimate the coefficients using the least squares criterion, which minimizes the residual sum of squares (RSS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a regularized linear regression model, we minimize the sum of RSS and a \"penalty term\" that penalizes coefficient size.\n",
    "\n",
    "**Ridge regression** (or \"L2 regularization\") minimizes: $$\\text{RSS} + \\alpha \\sum_{j=1}^p \\beta_j^2$$\n",
    "\n",
    "**Lasso regression** (or \"L1 regularization\") minimizes: $$\\text{RSS} + \\alpha \\sum_{j=1}^p |\\beta_j|$$\n",
    "\n",
    "- $p$ is the number of features.\n",
    "- $\\beta_j$ is a model coefficient.\n",
    "- $\\alpha$ is a tuning parameter:\n",
    "    - A tiny $\\alpha$ imposes no penalty on the coefficient size, and is equivalent to a normal linear regression model.\n",
    "    - Increasing the $\\alpha$ penalizes the coefficients and thus shrinks them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lasso-and-ridge-path-diagrams\"></a>\n",
    "### Lasso and Ridge Path Diagrams\n",
    "\n",
    "A larger alpha (toward the left of each diagram) results in more regularization:\n",
    "\n",
    "- Lasso regression shrinks coefficients all the way to zero, thus removing them from the model.\n",
    "- Ridge regression shrinks coefficients toward zero, but they rarely reach zero.\n",
    "\n",
    "Source code for the diagrams: [Lasso regression](http://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_lars.html) and [Ridge regression](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ridge_path.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lasso and Ridge Coefficient Plots](./assets/lasso_ridge_path.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"advice-for-applying-regularization\"></a>\n",
    "### Advice for Applying Regularization\n",
    "\n",
    "**Should features be standardized?**\n",
    "\n",
    "- Yes, because otherwise, features would be penalized simply because of their scale.\n",
    "- Also, standardizing avoids penalizing the intercept, which wouldn't make intuitive sense.\n",
    "\n",
    "**How should you choose between lasso regression and ridge regression?**\n",
    "\n",
    "- Lasso regression is preferred if we believe many features are irrelevant or if we prefer a sparse model.\n",
    "- Ridge can work particularly well if there is a high degree of multicollinearity in your model.\n",
    "- If model performance is your primary concern, it is best to try both.\n",
    "- Elastic net regression is a combination of lasso regression and ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ridge-regression\"></a>\n",
    "### Ridge Regression\n",
    "\n",
    "- [Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) documentation\n",
    "- **alpha:** must be positive, increase for more regularization\n",
    "- **normalize:** scales the features (without using StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T18:23:07.564558Z",
     "start_time": "2024-03-12T18:23:07.533528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Include dummy variables for season in the model.\n",
    "feature_cols = ['temp', 'atemp', 'season_2', 'season_3', 'season_4', 'humidity', ]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "X = bikes_dummies[feature_cols]\n",
    "y = bikes_dummies.total_rentals\n",
    "X_transform = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T18:23:42.032864Z",
     "start_time": "2024-03-12T18:23:42.005218Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T18:23:42.820641Z",
     "start_time": "2024-03-12T18:23:42.791643Z"
    }
   },
   "outputs": [],
   "source": [
    "# alpha=0 is equivalent to linear regression.\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Instantiate the model.\n",
    "#(Alpha of zero has no regularization strength, essentially a basic linear regression.)\n",
    "ridgereg = Ridge(alpha=0)\n",
    "\n",
    "# Fit the model.\n",
    "ridgereg.fit(X_train, y_train)\n",
    "\n",
    "# Predict with fitted model.\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T18:23:46.624320Z",
     "start_time": "2024-03-12T18:23:46.596377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Coefficients for a non-regularized linear regression\n",
    "list(zip(feature_cols, ridgereg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret these coefficients we need to convert them back to original units, which is a reason to do normalization by hand. However, in this form the coefficients have a special meaning. The intercept is now the average of our outcome, and the magnitude of each coefficient in the model is a measure of how important it is in the model. We call this feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T18:25:47.124155Z",
     "start_time": "2024-03-12T18:25:47.093394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try alpha=0.1.\n",
    "ridgereg = Ridge(alpha=1000)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T18:25:51.420072Z",
     "start_time": "2024-03-12T18:25:51.391389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Examine the coefficients.\n",
    "list(zip(feature_cols, ridgereg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the MSE barely changed, we can see there are significant changes in the weight of our coefficients.  Particularly `season_2` whose coefficient has greatly decreased toward 0.\n",
    "\n",
    "Fitting and using a Lasso Regression in scikit-learn is very similar.  \n",
    "\n",
    "In addition to the typical [lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) and [ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) there is a third type of regression, [Elastic Net](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) which combines the penalties of the ridge and lasso methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-linear-regression-with-other-models\"></a>\n",
    "## Comparing Linear Regression With Other Models\n",
    "\n",
    "Advantages of linear regression:\n",
    "\n",
    "- Simple to explain.\n",
    "- Highly interpretable.\n",
    "- Model training and prediction are fast.\n",
    "- No tuning is required (excluding regularization).\n",
    "- Features don't need scaling.\n",
    "- Can perform well with a small number of observations.\n",
    "- Well understood.\n",
    "\n",
    "Disadvantages of linear regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the response.\n",
    "- Performance is (generally) not competitive with the best supervised learning methods due to high bias.\n",
    "- Can't automatically learn feature interactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
